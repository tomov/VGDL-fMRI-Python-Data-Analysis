{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersubject Correlation Analysis (ISC)\n",
    "\n",
    "The BOLD signal contains noise. Here, we calculate correlations between subjects to reduce noise and estimate task-relevant signals.\n",
    "\n",
    "---\n",
    "\n",
    "1. Load data in notebook\n",
    "2. Brief fMRI data exploration\n",
    "3. Do ISC analysis; see (Chen et al., 2017) and [Brainiak ISC tutorial](https://brainiak.org/tutorials/10-isc/)\n",
    "    - (A) On the toy datasets from Brainiak\n",
    "    - (B) On our own data\n",
    "    \n",
    "[Brainiak ISC analyasis documentation](https://brainiak.org/docs/brainiak.html#module-brainiak.isc)\n",
    "\n",
    "[Brainiak specific examples](https://github.com/brainiak/brainiak/tree/master/examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISC on toy dataset ('Pieman')\n",
    "\n",
    "### Workflow\n",
    "\n",
    "Always perform the following steps\n",
    "\n",
    "1. Prepare the data (define data path etc)\n",
    "2. Compute ISC\n",
    "3. Permutation test ISC\n",
    "4. Compute IFSC\n",
    "5. Cluster IFSC results\n",
    "6. Perform IFSC permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn import surface\n",
    "from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker, NiftiLabelsMasker\n",
    "import nibabel as nib\n",
    "\n",
    "import brainiak\n",
    "from brainiak import image, io\n",
    "#from brainiak.isc import isc, isfc, permutation_isc # getting error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "%autosave 5\n",
    "%matplotlib inline\n",
    "sns.set(style = 'white', context='talk', font_scale=1, rc={\"lines.linewidth\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data prep\n",
    "\n",
    "-  All subjects must be in the same anatomical space for analysis.\n",
    "- create a whole-brain mask\n",
    "- outcome of this is an array of anatomically-aligned and temporally-aligned brain data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define data path and check if dir is valid\n",
    "pieman2_dir = '/Users/Daphne/Desktop/Pieman2' # local directory\n",
    "os.path.exists(pieman2_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_mask = os.path.join(pieman2_dir, 'masks/')\n",
    "mask_name = os.path.join(dir_mask, 'avg152T1_gray_3mm.nii.gz')\n",
    "all_task_names = ['word', 'intact1']\n",
    "all_task_des = ['word level scramble', 'intact story']\n",
    "n_subjs_total = 10\n",
    "group_assignment_dict = {task_name: i for i, task_name in enumerate(all_task_names)}\n",
    "\n",
    "# Where do you want to store the data\n",
    "dir_out = os.getcwd() + str('/pieman2_data')\n",
    "if not os.path.exists(dir_out): # make data folder within current working directory\n",
    "    os.makedirs(dir_out)\n",
    "    print('Dir %s created ' % dir_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the number of subjects per condition to make this notebook faster \n",
    "upper_limit_n_subjs = 10\n",
    "\n",
    "def get_file_names(data_dir_, task_name_, verbose = False):\n",
    "    \"\"\"\n",
    "    Get all the participant file names\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir_ [str]: the data root dir\n",
    "    task_name_ [str]: the name of the task \n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    fnames_ [list]: file names for all subjs\n",
    "    \"\"\"\n",
    "    c_ = 0 \n",
    "    fnames_ = []\n",
    "    # Collect all file names \n",
    "    for subj in range(1, n_subjs_total): \n",
    "        fname = os.path.join(\n",
    "            data_dir_, 'sub-%.3d/func/sub-%.3d-task-%s.nii.gz' % (subj, subj, task_name_))\n",
    "        \n",
    "        # If the file exists\n",
    "        if os.path.exists(fname):\n",
    "            \n",
    "            # Add to the list of file names \n",
    "            fnames_.append(fname)\n",
    "            if verbose: \n",
    "                print(fname)\n",
    "            c_+= 1\n",
    "            if c_ >= upper_limit_n_subjs: \n",
    "                break\n",
    "    return fnames_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load brain template\"\"\"\n",
    "\n",
    "# Load the brain mask\n",
    "brain_mask = io.load_boolean_mask(mask_name)\n",
    "\n",
    "# Get the list of nonzero voxel coordinates\n",
    "coords = np.where(brain_mask)\n",
    "\n",
    "# Load the brain nii image\n",
    "brain_nii = nib.load(mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cd5a0044d944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Concatenate all of the masked images across participants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     bold[task_name] = image.MaskedMultiSubjectData.from_masked_images(\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmasked_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Convert nans into zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/FMRI/lib/python3.6/site-packages/brainiak/image.py\u001b[0m in \u001b[0;36mfrom_masked_images\u001b[0;34m(cls, masked_images, n_sub)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \"\"\"\n\u001b[1;32m     62\u001b[0m         \u001b[0mimages_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfirst_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         for n_images, image in enumerate(itertools.chain([first_image],\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"load bold data\"\"\"\n",
    "\n",
    "# load the functional data \n",
    "fnames = {}\n",
    "images = {}\n",
    "masked_images = {}\n",
    "bold = {}\n",
    "group_assignment = []\n",
    "n_subjs = {}\n",
    "\n",
    "for task_name in all_task_names: \n",
    "    fnames[task_name] = get_file_names(pieman2_dir, task_name)\n",
    "    images[task_name] = io.load_images(fnames[task_name]) \n",
    "    masked_images[task_name] = image.mask_images(images[task_name], brain_mask) \n",
    "    # Concatenate all of the masked images across participants  \n",
    "    bold[task_name] = image.MaskedMultiSubjectData.from_masked_images(\n",
    "        masked_images[task_name], len(fnames[task_name])\n",
    "    )\n",
    "    # Convert nans into zeros\n",
    "    bold[task_name][np.isnan(bold[task_name])] = 0\n",
    "    # compute the group assignment label \n",
    "    n_subjs_this_task = np.shape(bold[task_name])[-1]\n",
    "    group_assignment += list(\n",
    "        np.repeat(group_assignment_dict[task_name], n_subjs_this_task)\n",
    "    )\n",
    "    n_subjs[task_name] = np.shape(bold[task_name])[-1]\n",
    "    print('Data loaded: {} \\t shape: {}' .format(task_name, np.shape(bold[task_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at that data\n",
    "\n",
    "### TODO: exercises \n",
    "\n",
    "Brain template\n",
    "- Report the shape of brain_nii, brain_mask\n",
    "- Visualize brain_nii and brain_mask by plotting the 30th slice along the Z dimension.\n",
    "- Describe what coords refers to\n",
    "- Visualize coords with a 3d plot. For this, only plot every 10th point, otherwise the plot will be slow to load.\n",
    "\n",
    "Brain data\n",
    "- Inspect the shape of bold. How many subjects do we have for each task condition? \n",
    "- Do different subjects have the same number of TRs/voxels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_nii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "1*brain_mask # brain mask is a binary matrix that selects the ROI's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coords # coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.scatter3D(coords[0], coords[1], coords[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_coords = [(x_coord, y_coord, z_coord) for x_coord in x for y_coord in y for z_coord in [10]]\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.scatter3D(slice_coords[0], slice_coords[1], slice_coords[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coords = pd.DataFrame([x, y, z])[:,:,30]\n",
    "plt.scatter(df_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.scatter3D(coords[0], coords[1], 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98508, 300, 8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bold['intact1'].shape # voxels, ... , participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute ISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'brainiak' has no attribute 'isc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-aea41f1169da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0misc_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_task_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0misc_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrainiak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairwise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Shape of %s condition:'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misc_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'brainiak' has no attribute 'isc'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FMRI",
   "language": "python",
   "name": "fmri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
