{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import h5py\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from nilearn import datasets, image\n",
    "from nilearn import surface\n",
    "from nilearn import plotting\n",
    "from nilearn import input_data\n",
    "\n",
    "from nilearn.input_data import NiftiMasker, NiftiLabelsMasker\n",
    "from nibabel.affines import apply_affine\n",
    "import nibabel as nib\n",
    "import time\n",
    "\n",
    "from brainiak import image, io\n",
    "from brainiak.isc import isc, isfc, permutation_isc\n",
    "from brainiak.isc import compute_summary_statistic\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d \n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "from importlib import reload \n",
    "import scipy.io as sio\n",
    "from scipy import stats\n",
    "from numpy.linalg import inv\n",
    "from numpy import inf\n",
    "from scipy import stats\n",
    "\n",
    "# import own functions\n",
    "import utils\n",
    "reload(utils)\n",
    "\n",
    "sns.set(style = 'white', context='poster', rc={\"lines.linewidth\": 2.5})\n",
    "sns.set(palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Specify path to load masks etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../fMRI_analysis_jiajia/data/' # @Jiajia put the path here\n",
    "\n",
    "# mask_nii is the functional mask, this selects the brain voxels\n",
    "mask_nii = nib.load(os.path.join(path, 'mask.nii')) \n",
    "# this where we plot our mask ON (sometimes called brain_nii) - the anatomical/structural image\n",
    "mean_nii = nib.load(os.path.join(path, 'mean.nii')) \n",
    "\n",
    "# inverse of the affine matrix: mni2cor\n",
    "inv_affine = inv(mask_nii.affine) # get the transformation matrix\n",
    "\n",
    "# load mask and get voxel coordinates\n",
    "mask_arr = np.load(path+'mask_arr.npy') # all masks are the same\n",
    "mask_mat = mask_arr[0] # so we can pick any one from the array\n",
    "coords_mat = np.array(np.where(mask_mat == 1)) # so need one set of voxel coordinates for all\n",
    "coords_mat[[0, 2]] = coords_mat[[2, 0]] # exchange the rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @Jiajia adapt this to get the residuals for each subject in `residuals`\n",
    "\n",
    "> Sanity check: `residuals.shape` should be (1698, 220075, 8) - (TRs, voxels, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Get residuals for subject 1\n",
      "1\n",
      "Get residuals for subject 2\n",
      "2\n",
      "Get residuals for subject 3\n",
      "3\n",
      "Get residuals for subject 4\n",
      "4\n",
      "Get residuals for subject 5\n",
      "5\n",
      "Get residuals for subject 6\n",
      "6\n",
      "Get residuals for subject 7\n",
      "7\n",
      "Get residuals for subject 8\n"
     ]
    }
   ],
   "source": [
    "residuals = [] # for all subjects \n",
    "\n",
    "# change filename to subject #\n",
    "data_dir = '/ncf/gershman/Lab/scripts/matlab/VGDL_fMRI/mat/' # @Jiajia put directory of folder in which the residuals are here\n",
    "\n",
    "num_subjects = 8\n",
    "\n",
    "for i in range(num_subjects):\n",
    "    print(i)\n",
    "    idx = i+1\n",
    "\n",
    "    filename = 'residuals_glm9_subjk_smooth.mat' # update filename with subject number\n",
    "    filename = filename.replace('k', str(idx))\n",
    "    \n",
    "    data = h5py.File(data_dir + filename,'r')\n",
    "    print(f'Get residuals for subject {idx}')\n",
    "    # take the residuals from .mat file\n",
    "    residuals_sub_k = data['R'].value\n",
    "    \n",
    "    # append to list\n",
    "    residuals.append(residuals_sub_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swap axes if needed @jiajia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1698, 220075, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals = np.swapaxes(residuals,0,2)\n",
    "residuals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pick seeds @jiajia just run this :)\n",
    "\n",
    "- We loaded the whole-brain residuals\n",
    "- Now, we pick ROIs (== seed voxel) and correlate their activity with other voxels in the brain\n",
    "- If we find voxels that are correlated with a seed ROI, this suggests that these voxels are functionally connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theory ENCODING voxels\n",
    "R_IFG_Tri_E = [42, 28, 26]\n",
    "L_Insula_E = [-30, 28, 2]\n",
    "R_DMPFC_E = [6, 38, 40]\n",
    "L_IFG_Tri_E = [-50, 44, 12]\n",
    "L_MTG_E = [-64, -50, 4]\n",
    "R_MTG_E = [58, -36, 8]\n",
    "Roi_1A = [48, 34,  8]\n",
    "\n",
    "# Theory UPDATING voxels\n",
    "R_IFG_Oper_U = [48, 12, 28]\n",
    "L_PPC_U = [-56, -32, 46]\n",
    "R_IFG_Tri_U = [52, 38, 16]\n",
    "R_AG_U = [32, -60, 34]\n",
    "L_Fusiform_U = [-40, -58, -12]\n",
    "L_IFG_Oper_U = [-42, 4, 28]\n",
    "R_PHC_U = [26, -42, -8]\n",
    "\n",
    "# control voxels\n",
    "# tip: can always try the contralateral ROIs: [-x y z]\n",
    "L_lingual = [2, -86, 4]\n",
    "Occipital = [-36 -88 -12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to map points to roi names\n",
    "encoding_roi_dict = {'R_IFG_Tri_E':R_IFG_Tri_E, 'L_Insula_E':L_Insula_E, 'R_DMPFC_E':R_DMPFC_E,\n",
    "                     'L_IFG_Tri_E':L_IFG_Tri_E, 'L_MTG_E':L_MTG_E, 'R_MTG_E':R_MTG_E, 'Roi_1A ':Roi_1A \n",
    "                    }\n",
    "\n",
    "updating_roi_dict = {'R_IFG_Oper_U':R_IFG_Oper_U, 'L_PPC_U':L_PPC_U, 'R_IFG_Tri_U':R_IFG_Tri_U,\n",
    "                     'R_AG_U':R_AG_U, 'L_Fusiform_U':L_Fusiform_U, 'L_IFG_Oper_U':L_IFG_Oper_U, \n",
    "                     'R_PHC_U':R_PHC_U\n",
    "                    }\n",
    "\n",
    "# combine in one\n",
    "EU_dict = {**encoding_roi_dict, **updating_roi_dict}\n",
    "\n",
    "# map control voxels to names\n",
    "control_dict = {'control vox (left lingual)':L_lingual, 'control vox (Occipital)':Occipital}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coordinates correspond to voxel: 146217.\n",
      "The coordinates correspond to voxel: 89655.\n",
      "The coordinates correspond to voxel: 175423.\n",
      "The coordinates correspond to voxel: 114273.\n",
      "The coordinates correspond to voxel: 91966.\n",
      "The coordinates correspond to voxel: 102081.\n",
      "The coordinates correspond to voxel: 104340.\n",
      "The coordinates correspond to voxel: 150132.\n",
      "The coordinates correspond to voxel: 184359.\n",
      "The coordinates correspond to voxel: 123560.\n",
      "The coordinates correspond to voxel: 160565.\n",
      "The coordinates correspond to voxel: 53783.\n",
      "The coordinates correspond to voxel: 149930.\n",
      "The coordinates correspond to voxel: 63462.\n"
     ]
    }
   ],
   "source": [
    "# get the voxel indices for the theory encoding and theory updating regions\n",
    "encoding_voxels = []\n",
    "updating_voxels = []\n",
    "\n",
    "# ENCODING ROIs\n",
    "for key, value in encoding_roi_dict.items():\n",
    "\n",
    "    coords_mni = value\n",
    "    #print(coords_mni)\n",
    "    \n",
    "    coords_natv = apply_affine(aff=inv_affine, pts=coords_mni) # from mni2cor\n",
    "    vox_num = utils.get_vox_from_coords(coords_mat, coords_natv) # corresponding voxel\n",
    "    \n",
    "    encoding_voxels.append(vox_num)\n",
    "\n",
    "# UPDATING ROIs\n",
    "for key, value in updating_roi_dict.items():\n",
    "\n",
    "    coords_mni = value\n",
    "    #print(coords_mni)\n",
    "    \n",
    "    coords_natv = apply_affine(aff=inv_affine, pts=coords_mni) # from mni2cor\n",
    "    vox_num = utils.get_vox_from_coords(coords_mat, coords_natv) # corresponding voxel\n",
    "    \n",
    "    updating_voxels.append(vox_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Correlation matrix and connectome\n",
    "\n",
    "> Correlate the theory updating voxels with the theory encoding voxels\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1RSGslepHFghu4LpvuwmRkcwdRCEYD4DP\" style=\"height:200px\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[146217, 89655, 175423, 114273, 91966, 102081, 104340]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[150132, 184359, 123560, 160565, 53783, 149930, 63462]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updating_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_one_sub(R, encoding_voxels, updating_voxels):\n",
    "    '''\n",
    "    Correlates the time series between two sets of voxels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    R: the residuals for one subject\n",
    "    updating_voxels: the indices of the updating voxels\n",
    "    encoding_voxels: the indices of the encoding voxels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    corr_matrix: asymmetric correlation matrix for that subject\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # select the voxels from the residuals\n",
    "    updating_time_series = R[:, updating_voxels]\n",
    "    encoding_time_series = R[:, encoding_voxels]\n",
    "\n",
    "    N = len(encoding_time_series[1])\n",
    "    corr_matrix = np.zeros((N,N))\n",
    "\n",
    "\n",
    "    for i in range(N): # iterate through voxels (see img above)\n",
    "\n",
    "        corr_col = []\n",
    "        # pick the ith column from encoding \n",
    "        encoding_vec = encoding_time_series[:, i]\n",
    "\n",
    "        # correlate it with each col (j) from updating time series\n",
    "        for j in range(N):\n",
    "\n",
    "            updating_vec = updating_time_series[:, j]\n",
    "\n",
    "            # correlate column i with column j\n",
    "            corr, _ = stats.pearsonr(encoding_vec, updating_vec)\n",
    "\n",
    "            corr_col.append(round(corr,2)) \n",
    "\n",
    "        corr_matrix[:, i] = corr_col # insert correlations into correlation matrix\n",
    "#         print(f'--- Theory encoding col {i} ---')\n",
    "#         print(corr_matrix)\n",
    "\n",
    "    return corr_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @jiajia I could not check this. `residuals` should be (1698, 220075, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1698, 220075, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corr_matrices = []\n",
    "\n",
    "for i in range(num_subjects):\n",
    "    # select residuals for one subject\n",
    "    R = residuals[:, :, i] # all TRs, all voxels, one subject\n",
    "    \n",
    "    corr_matrix = correlate_one_sub(R, encoding_voxels, updating_voxels) # call above function\n",
    "    \n",
    "    # append to list\n",
    "    all_corr_matrices.append(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Jiajia save this and send to me :)\n",
    "np.save('all_corr_matrices', all_corr_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create symmetric matrices for connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corr_matrices_sym = []\n",
    "\n",
    "all_roi_voxels = encoding_voxels + updating_voxels # combine voxel indices\n",
    "\n",
    "\n",
    "for i in range(num_subjects):\n",
    "    # select residuals for one subject\n",
    "    R = residuals[:, :, i] # all TRs, all voxels, one subject\n",
    "    \n",
    "    all_roi_time_series = R[:, all_roi_voxels]\n",
    "    \n",
    "    df = pd.DataFrame(all_roi_time_series) # convert to df\n",
    "    sym_corr_matrix = df.corr('pearson') # correlate all cols\n",
    "    \n",
    "    \n",
    "    all_corr_matrices_sym.append(sym_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Jiajia save this and send to me :)\n",
    "np.save('all_corr_matrices_sym', all_corr_matrices_sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @Jiajia lastly, having this would be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1698, 14)\n",
      "(1698, 14)\n",
      "(1698, 14)\n",
      "(1698, 14)\n",
      "(1698, 14)\n",
      "(1698, 14)\n",
      "(1698, 14)\n",
      "(1698, 14)\n"
     ]
    }
   ],
   "source": [
    "residuals_roi_voxels = []\n",
    "\n",
    "all_roi_voxels = encoding_voxels + updating_voxels # combine voxel indices\n",
    "\n",
    "for i in range(num_subjects):\n",
    "    # select residuals for one subject\n",
    "    R = residuals[:, :, i] # all TRs, all voxels, one subject\n",
    "    \n",
    "    all_roi_time_series = R[:, all_roi_voxels] # take only voxels of interest\n",
    "    print(all_roi_time_series.shape) # @jiajia this should be: (1698, 14)\n",
    "    \n",
    "    residuals_roi_voxels.append(all_roi_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1698, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(residuals_roi_voxels).swashape # @jiajia this should be (1698, 14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Jiajia save this and send to me :)\n",
    "np.save('residuals_roi_voxels', residuals_roi_voxels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
