{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISC analysis with levels\n",
    "\n",
    "Remark: could be the most promising.\n",
    "\n",
    "`beta_series glm25 subj* nosmooth`\n",
    "\n",
    "## Main goals\n",
    "\n",
    "The BOLD signal contains noise. Here, we calculate correlations between subjects to reduce noise and estimate task-relevant signals. Want to find brain regions where the same levels of activity are displayed. Key predictions are that, in the theory encoding region, the ISC should:\n",
    "\n",
    "1. Be highest for same levels, medium for same games, and lowest for random (shuffled) games\n",
    "2. Increase over levels of the same game\n",
    "\n",
    "---\n",
    "\n",
    "## Outline\n",
    "\n",
    "0. Load data in\n",
    "1. Preprocess data\n",
    "2. Reorder BOLD data based on names\n",
    "3. ISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn import surface\n",
    "from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker, NiftiLabelsMasker\n",
    "import nibabel as nib\n",
    "\n",
    "from brainiak import image, io\n",
    "from brainiak.isc import isc, isfc, permutation_isc\n",
    "from brainiak.isc import compute_summary_statistic\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d \n",
    "import seaborn as sns \n",
    "import hdf5storage\n",
    "import mat73\n",
    "import pandas as pd\n",
    "\n",
    "%autosave 30\n",
    "%matplotlib inline\n",
    "sns.set(style = 'white', context='talk', font_scale=1, rc={\"lines.linewidth\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load in data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/Users/Daphne/Desktop/beta_series/' # local directory\n",
    "# specify filename\n",
    "filename = 'beta_series_glm25_subj1_nosmooth.mat'\n",
    "\n",
    "os.path.exists(data_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#refs#', 'B', 'Vmask', 'mask', 'names']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each subject is a separate file so\n",
    "subject = h5py.File(data_dir+filename,'r')\n",
    "\n",
    "list(subject.keys()) # these are the variables in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_variable(file, item):\n",
    "\n",
    "    '''\n",
    "    Converts matlab cell array in the form \"<HDF5 object reference>\" to list of strings.\n",
    "\n",
    "    IN\n",
    "\n",
    "    file: the path + filename \n",
    "    item: the variable in the dataset that needs to be decoded\n",
    "\n",
    "    RETURNS\n",
    "\n",
    "    readable_data: np array of strings\n",
    "    '''\n",
    "\n",
    "    # Open file                                                                                    \n",
    "    myfile = h5py.File(file,'r')\n",
    "    variable = myfile[item] # get the names variable\n",
    "\n",
    "    readable_data = [] # store the ne\n",
    "\n",
    "\n",
    "    for var in variable: # encode and decode the objects, 18 per subject\n",
    "        for v in var: # Read the references  \n",
    "\n",
    "            #print(v)\n",
    "            ds = myfile[v]\n",
    "            #print(ds)\n",
    "            data = ds[:]\n",
    "\n",
    "            # store the decoded data\n",
    "            word = []\n",
    "            \n",
    "            for i in data:\n",
    "                letter = str(chr(i))  # the chr() function returns the character that represents the specified unicode.\n",
    "                word.append(letter)\n",
    "            word = ''.join(word) # join list of strings\n",
    "            \n",
    "            readable_data.append(word)\n",
    "            \n",
    "    return np.array(readable_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data for subject 1\n",
      "Get data for subject 2\n",
      "Get data for subject 3\n",
      "Get data for subject 4\n",
      "Get data for subject 5\n",
      "Get data for subject 6\n",
      "Get data for subject 7\n",
      "Get data for subject 8\n"
     ]
    }
   ],
   "source": [
    "num_subjects = 8\n",
    "\n",
    "B_data = []\n",
    "mask_data = []\n",
    "Vmask_data = []\n",
    "levels_data = []\n",
    "\n",
    "for i in range(num_subjects):\n",
    "    idx = i+1\n",
    "    \n",
    "    # change filename to subject #\n",
    "    data_dir = '/Users/Daphne/Desktop/beta_series/'\n",
    "    filename = 'beta_series_glm25_subjk_nosmooth.mat'\n",
    "    filename = filename.replace('k', str(idx))\n",
    "    \n",
    "    subject = h5py.File(data_dir+filename,'r') \n",
    "    print(f'Get data for subject {idx}')\n",
    "    # load and save data for respective subject\n",
    "    B = subject['B'].value\n",
    "    mask = subject['mask'].value\n",
    "    Vmask = subject['Vmask']\n",
    "    \n",
    "    # === decode level names ===\n",
    "    names = decode_variable(data_dir+filename, 'names')\n",
    "    \n",
    "    # append to lists\n",
    "    B_data.append(B)\n",
    "    mask_data.append(mask)\n",
    "    Vmask_data.append(Vmask)\n",
    "    levels_data.append(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179595, 54)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_data[0].shape # voxels x levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 95, 79)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels_data[0].shape # 54 levels (18x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sn(1) vgfmri3_chase_run_1_block_1_instance_1*bf(1)',\n",
       "       'Sn(1) vgfmri3_chase_run_1_block_1_instance_2*bf(1)',\n",
       "       'Sn(1) vgfmri3_chase_run_1_block_1_instance_3*bf(1)',\n",
       "       'Sn(1) vgfmri3_lemmings_run_1_block_2_instance_1*bf(1)',\n",
       "       'Sn(1) vgfmri3_lemmings_run_1_block_2_instance_2*bf(1)',\n",
       "       'Sn(1) vgfmri3_lemmings_run_1_block_2_instance_3*bf(1)',\n",
       "       'Sn(1) vgfmri3_bait_run_1_block_3_instance_1*bf(1)',\n",
       "       'Sn(1) vgfmri3_bait_run_1_block_3_instance_2*bf(1)',\n",
       "       'Sn(1) vgfmri3_bait_run_1_block_3_instance_3*bf(1)',\n",
       "       'Sn(2) vgfmri3_plaqueAttack_run_2_block_1_instance_1*bf(1)'],\n",
       "      dtype='<U57')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels_data[0][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing\n",
    "\n",
    "1. Clean the level name strings\n",
    "\n",
    "<font color=red> TODO: Reordering mistake. Figure out meaning of SN() and reimplement. </font>\n",
    "\n",
    "2. Reorder the BOLD data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_names(s):\n",
    "    '''\n",
    "    Removes parts of the string to make it more orderly and easier to rearrange.\n",
    "    '''\n",
    "\n",
    "    for r in (('vgfmri3_', ''), ('*bf(1)', ''), ('Sn(', '')):\n",
    "        s = s.replace(*r)\n",
    "        \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_shape(B_s, names_s):\n",
    "    \n",
    "    '''\n",
    "    Massages data into right shape to perform ISC: [TRs, voxels, subjects] - bunch of stacked matrices\n",
    "    \n",
    "    IN\n",
    "    \n",
    "    B: the bold data for subject s\n",
    "    names: the order of the levels for subject s\n",
    "    \n",
    "    OUT\n",
    "    \n",
    "    dfOrdered: the ordered df, just to sanity check the reordering\n",
    "    B_ordered: the ordered B array [levels, voxels]\n",
    "    '''\n",
    "    \n",
    "    #print(B_s.shape)\n",
    "    \n",
    "    # cleanup the level names first, remove stuff\n",
    "    level_names = []\n",
    "\n",
    "    for name in names_s:\n",
    "        stripped_name = cleanup_names(name)\n",
    "        level_names.append(stripped_name)\n",
    "    \n",
    "    #print(level_names)\n",
    "    \n",
    "    # read in B as pandas df\n",
    "    df = pd.DataFrame(B_s)\n",
    "    df.insert(0, 'level', level_names) # insert level names as first col\n",
    "    \n",
    "    dfOrdered = df.sort_values(by='level') # reorder the matrix based on the 'levels' column\n",
    "    dfBold = dfOrdered.drop('level', 1) # don't need the column with the level names anymore\n",
    "    \n",
    "    B_ordered = dfBold.values # convert df to numpy array\n",
    "    \n",
    "    return dfOrdered, B_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess fMRI data for subject 1\n",
      "Preprocess fMRI data for subject 2\n",
      "Preprocess fMRI data for subject 3\n",
      "Preprocess fMRI data for subject 4\n",
      "Preprocess fMRI data for subject 5\n",
      "Preprocess fMRI data for subject 6\n",
      "Preprocess fMRI data for subject 7\n",
      "Preprocess fMRI data for subject 8\n"
     ]
    }
   ],
   "source": [
    "ISC_data = []\n",
    "ordered_dfs = []\n",
    "\n",
    "for s in range(num_subjects):\n",
    "    \n",
    "    print(f'Preprocess fMRI data for subject {s+1}')\n",
    "    # get the betas and game order from this\n",
    "    B_s = B_data[s].T # transpose to get [blocks, voxels]\n",
    "    names_s = levels_data[s]\n",
    "    \n",
    "    dfOrdered, B_ordered = get_in_shape(B_s, names_s)\n",
    "    \n",
    "    ISC_data.append(B_ordered)\n",
    "    ordered_dfs.append(dfOrdered)\n",
    "    \n",
    "ISC_arr = np.array(ISC_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 54, 179595)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISC_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 179595, 8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISC_arr = np.swapaxes(ISC_arr, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "ISC_arr = np.swapaxes(ISC_arr, 1, 2)\n",
    "\n",
    "ISC_arr.shape # [levels, voxels, subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiakEnv",
   "language": "python",
   "name": "brainiakenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
