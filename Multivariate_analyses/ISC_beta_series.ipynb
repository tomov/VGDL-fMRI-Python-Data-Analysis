{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and workflow\n",
    "\n",
    "## Main goals\n",
    "\n",
    "The BOLD signal contains noise. Here, we calculate correlations between subjects to reduce noise and estimate task-relevant signals. Want to find brain regions where the same levels of activity are displayed. Key predictions are that, in the theory encoding region, the ISC should:\n",
    "\n",
    "1. Be highest for same levels, medium for same games, and lowest for random (shuffled) games\n",
    "2. Increase over levels of the same game\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Load data in notebook (we are dealing with `.mat` files) (**Remark.** note that files are different (glm1 != glm24)\n",
    "2. Do fMRI data exploration (how does the structure look like, etc.)\n",
    "    - preprocessing\n",
    "3. Do ISC analysis; see (Chen et al., 2017) and [Brainiak ISC tutorial](https://brainiak.org/tutorials/10-isc/)\n",
    "4. Do Searchlight analysis []\n",
    "\n",
    "[Brainiak ISC analyasis documentation](https://brainiak.org/docs/brainiak.html#module-brainiak.isc)\n",
    "\n",
    "[Brainiak specific examples](https://github.com/brainiak/brainiak/tree/master/examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainiak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn import surface\n",
    "from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker, NiftiLabelsMasker\n",
    "import nibabel as nib\n",
    "\n",
    "from brainiak import image, io\n",
    "#from brainiak.isc import isc, isfc, permutation_isc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "%autosave 5\n",
    "%matplotlib inline\n",
    "sns.set(style = 'white', context='talk', font_scale=1, rc={\"lines.linewidth\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/Users/Daphne/Desktop/beta_series/' # local directory\n",
    "os.path.exists(data_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from [here](https://stackoverflow.com/questions/874461/read-mat-files-in-python) and [scipy docu](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.loadmat.html)\n",
    "```\n",
    "Neither scipy.io.savemat, nor scipy.io.loadmat work for MATLAB arrays version 7.3. But the good part is that MATLAB version 7.3 files are hdf5 datasets. So they can be read using a number of tools, including NumPy.\n",
    "```\n",
    "\n",
    "[h5py documentation](http://docs.h5py.org/en/stable/quick.html#core-concepts)\n",
    "\n",
    "We want to access the following variables in the dataset:\n",
    "- `B = [blocks, voxels]`:  the average activity in each block\n",
    "- `names = [18,1]` : the names of the games\n",
    "- `Vmask = [1,1]` : can be used to convert mask to standardised brain coordinates\n",
    "- `mask = [79, 95, 79]` : binary mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify filename\n",
    "filename = 'beta_series_glm1_subj1_nosmooth.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#refs#', 'B', 'Vmask', 'mask', 'names']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each subject is a separate file so\n",
    "subject = h5py.File(data_dir+filename,'r')\n",
    "\n",
    "list(subject.keys()) # these are the variables in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13.67853355,   9.34046936,   8.19104671, ...,  13.98070717,\n",
       "          1.051754  ,   4.48804474],\n",
       "       [ 19.71709633,  14.8930378 ,  18.61097145, ...,   8.22801685,\n",
       "         -2.43646121,   3.49442911],\n",
       "       [  1.22297895,   3.4824307 ,   3.93117332, ...,   8.7571125 ,\n",
       "          5.50793028,   3.66078162],\n",
       "       ...,\n",
       "       [ -9.61049461, -38.04869461, -41.12371445, ...,  22.4010582 ,\n",
       "         17.33374023, -16.49692345],\n",
       "       [-14.54338264,  -4.19539356,  -0.50012857, ...,  -3.23373842,\n",
       "         -7.53230715, -12.56788921],\n",
       "       [-20.06606102,  -7.664783  ,  -4.73619652, ...,  26.66522789,\n",
       "         39.77856445,  40.31108856]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we read in all the variables of interest for a given subject\n",
    "B = subject['B'].value\n",
    "\n",
    "mask = subject['mask'].value\n",
    "names = subject['names'].value\n",
    "Vmask = subject['Vmask']\n",
    "\n",
    "# # alternatively, using dictionary syntax..\n",
    "# B = subject['B']\n",
    "# B[0]\n",
    "\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save data for subject 1\n",
      "Save data for subject 2\n",
      "Save data for subject 3\n",
      "Save data for subject 4\n",
      "Save data for subject 5\n",
      "Save data for subject 6\n",
      "Save data for subject 7\n",
      "Save data for subject 8\n"
     ]
    }
   ],
   "source": [
    "# get all the data for GLM1 (subjects 1-8)\n",
    "num_subjects = 8\n",
    "\n",
    "B_data = []\n",
    "mask_data = []\n",
    "Vmask_data = []\n",
    "names_data = []\n",
    "\n",
    "for i in range(num_subjects):\n",
    "    idx = i+1\n",
    "    \n",
    "    # change filename to subject #\n",
    "    data_dir = '/Users/Daphne/Desktop/beta_series/'\n",
    "    filename = 'beta_series_glm1_subjk_nosmooth.mat'\n",
    "    filename = filename.replace('k', str(idx))\n",
    "    \n",
    "    subject = h5py.File(data_dir+filename,'r') \n",
    "    print(f'Save data for subject {idx}')\n",
    "    # load and save data for respective subject\n",
    "    B = subject['B'].value\n",
    "    mask = subject['mask'].value\n",
    "    names = subject['names'].value\n",
    "    Vmask = subject['Vmask']\n",
    "    \n",
    "    # append to lists\n",
    "    B_data.append(B)\n",
    "    mask_data.append(mask)\n",
    "    Vmask_data.append(Vmask)\n",
    "    names_data.append(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data shapes (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179595, 18)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 95, 79)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/Vmask\" (8 members)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vmask_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stick to the recommended sequence of steps for running ISC using Brainiak\n",
    "1. **Data preparation**. Create a whole-brain mask. The outcome of this is an array of anatomically-aligned and temporally-aligned brain data.\n",
    "2. **Compute ISC**. The ISC function computes correlations across subjects for corresponding voxels in the mask. It uses the compute_correlation function in BrainIAK, which is optimized for fast execution (and was used in FCMA).\n",
    "3. **Permutation test for ISC**. Perform statistical analysis to determine significant correlation values for ISC\n",
    "\n",
    "\n",
    "# 1. Data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-041ef0631b76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the brain mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbrain_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_boolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Get the list of nonzero voxel coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mask_name' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"load brain template\"\"\"\n",
    "\n",
    "# Load the brain mask\n",
    "brain_mask = io.load_boolean_mask(mask_name)\n",
    "\n",
    "# Get the list of nonzero voxel coordinates\n",
    "coords = np.where(brain_mask)\n",
    "\n",
    "# Load the brain nii image\n",
    "brain_nii = nib.load(mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FMRI",
   "language": "python",
   "name": "fmri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
