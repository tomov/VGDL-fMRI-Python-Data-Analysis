{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searchlight analysis: think outside the box\n",
    "\n",
    "## This searchlight analysis is for the `non smooth betas`\n",
    "\n",
    "Recall that we think of each $\\beta$ as a point in high dimensional voxel space. We have to choose the voxels in which we want to do the MVPA for two main reasons:\n",
    "   \n",
    "1. **Cog neuro assumes the brain is made up of functional regions.** Based on the relevant unit of analysis (local regions). This idea about the brain as a modular structure comes from Cognitive Neuroscience.\n",
    "2. **Avoid overfitting.** From a statistical point of view, we prefer to have as few dimensions as possible. As such, we'd like to reduce the noise in our dataset by only including the most relevant voxels.\n",
    "\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1andZMeSCqfIQSfr7QwIRoYfHP0z7dGTD\" style=\"height:150px\"/>\n",
    "\n",
    "## Searchlight analysis\n",
    "\n",
    "from ([Joset et al., 2013](https://linkinghub.elsevier.com/retrieve/pii/S1053811913002917))\n",
    "\n",
    "- a type of Multivoxel Pattern Analysis (MVPA), sometimes referred to as *information mapping*.\n",
    "- a *searchlight* is a spatial moving window (kernel) that exhaustively searches the brain to localise representations. SA produces maps by measuring the information (read: variation in signal activity) in small spheres around each voxel.\n",
    "\n",
    "\n",
    "> We want to perform searchlight analyses with different ROI's such as:\n",
    "\n",
    "[from (Shuck et al., 2016)]()\n",
    "\n",
    "- PFC\n",
    "- \n",
    "\n",
    "[(Balaguer et al., 2016)]()\n",
    "\n",
    "- ...\n",
    "\n",
    "\n",
    "<font color=red> Finish this and plot the tstatistics like before, see jiajias work [here](https://github.com/tomov/VGDL-fMRI-Python-Data-Analysis/blob/master/fMRI_analysis_jiajia/RSA_Searchlight.ipynb) </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Searchlight workflow\n",
    "\n",
    "- The two main things that determine the speed of a searchlight: the **kernel algorithm** and the **amount of parallelization**.\n",
    "- Rule of thumb: start your searchlight analysis small!\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Create a mask of one voxel and run the searchlight interactively to check whether the code works.\n",
    "2. Use timestamps to extract the execution time\n",
    "3. Print the number of voxels that are passed to the searchlight function\n",
    "4. Run the searchlight as a job on the smallest unit of real data you have (a single run or single participant)\n",
    "5. Check the runtime and memory usage of this searchlight (e.g. on slurm: `sacct -j $JID --format=jobid,maxvmsize,elapsed`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "# Import libraries\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "from nilearn import plotting\n",
    "from brainiak.searchlight.searchlight import Searchlight\n",
    "from brainiak.fcma.preprocessing import prepare_searchlight_mvpa_data\n",
    "from brainiak import io\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d \n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "from importlib import reload \n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import scipy\n",
    "\n",
    "# import own functions\n",
    "import utils\n",
    "reload(utils)\n",
    "\n",
    "%autosave 30\n",
    "%matplotlib inline\n",
    "sns.set(style = 'white', context='talk', font_scale=1, rc={\"lines.linewidth\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify local path\n",
    "path = '/Users/Daphne/data/'\n",
    "\n",
    "# load betas \n",
    "all_bold_vol = np.load(path+'bold_data_levels_NS.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_nii is the functional mask, this selects the brain voxels\n",
    "mask_nii_NS = nib.load(os.path.join(path, 'mask_nii_NS.nii')) \n",
    "\n",
    "# the mask from the mask .mat files, use thisone to get the coordinates\n",
    "mask_mat_NS = np.load(path+'mask_mat_NS.npy')\n",
    "\n",
    "coords_mat = np.array(np.where(mask_mat_NS == 1)) # so need one set of voxel coordinates for all\n",
    "coords_mat[[0, 2]] = coords_mat[[2, 0]] # exchange the rows\n",
    "\n",
    "# this where we plot our mask ON (sometimes called brain_nii) - the anatomical/structural image\n",
    "mean_nii = nib.load(os.path.join(path, 'mean.nii')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mask = np.array(mask_nii_NS.dataobj)\n",
    "affine_mat = mask_nii_NS.affine\n",
    "dimsize = mask_nii_NS.header.get_zooms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 179595)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_mat.shape # dimensions by voxel number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare the data and set SA parameters \n",
    "\n",
    "- We get the betas in the form `[x,y,z, voxel intensity]`, going from 3D to 4D arr.\n",
    "\n",
    "TODO: sanity check going from 3D --> 4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([42]), array([28]), array([26]))\n"
     ]
    }
   ],
   "source": [
    "coords = tuple(coords_mat) # take the coordinates, make them tuple\n",
    "\n",
    "# ==== Make a mask of a voxel of choice (ROI) ===\n",
    "small_mask = np.zeros(brain_mask.shape)\n",
    "small_mask[42, 28, 26] = 1\n",
    "print(np.where(small_mask))\n",
    "\n",
    "Nrows = 54 # levels data has 54 rows (TRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol4D = mask_nii_NS.shape+(Nrows,)\n",
    "\n",
    "# For 8 subjects\n",
    "all_bold = []\n",
    "for sub_id in range(8):\n",
    "    isc_vol = np.zeros(vol4D)\n",
    "    bold_vol = all_bold_vol[:,:,sub_id]\n",
    "    for i in range(6):\n",
    "        for j in range(len(coords[0])):\n",
    "            # translate to 4D space in order to perform searchlight\n",
    "            # i = level\n",
    "            # j = voxel\n",
    "            isc_vol[(coords[0][j], coords[1][j], coords[2][j], i)] = bold_vol[i][j]\n",
    "            # (x,y,z,voxel)\n",
    "    all_bold.append(isc_vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searchlight parameters\n",
    "\n",
    "1. **data** = The brain data as a 4D volume.\n",
    "\n",
    "2. **mask** = A binary mask specifying the \"center\" voxels in the brain around which you want to perform searchlight analyses. A searchlight will be drawn around every voxel with the value of 1. Hence, if you chose to use the wholebrain mask as the mask for the searchlight procedure, the searchlight may include voxels outside of your mask when the \"center\" voxel is at the border of the mask. It is up to you to decide whether then to include these results.\n",
    "\n",
    "3. **bcvar** = An additional variable which can be a list, numpy array, dictionary, etc. you want to use in your searchlight kernel. For instance you might want the condition labels so that you can determine to which condition each 3D volume corresponds. If you don't need to broadcast anything, e.g, when doing RSA, set this to 'None'.\n",
    "\n",
    "4. **sl_rad** = The size of the searchlight's radius, excluding the center voxel. This means the total volume size of the searchlight, if using a cube, is defined as: ((2 * sl_rad) + 1) ^ 3. (*in voxels!*)\n",
    "\n",
    "5. **max_blk_edge** = When the searchlight function carves the data up into chunks, it doesn't distribute only a single searchlight's worth of data. Instead, it creates a block of data, with the edge length specified by this variable, which determines the number of searchlights to run within a job.\n",
    "\n",
    "6. **pool_size** = Maximum number of cores running on a block (typically 1).\n",
    "\n",
    "\n",
    "\n",
    "<font color=red> use the following radii: r = 2.6 voxels (4 mm); 4 voxels (6 mm); 6.6 voxels (10 mm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preset the variables\n",
    "data = all_bold\n",
    "mask = small_mask\n",
    "bcvar = None\n",
    "sl_rad = 4\n",
    "max_blk_edge = 5\n",
    "pool_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Execute searchlight window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup searchlight inputs\n",
      "Number of subjects: 8\n",
      "Input data shape: (79, 95, 79, 54)\n",
      "Input mask shape: (79, 95, 79)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start the clock to time searchlight\n",
    "begin_time = time.time()\n",
    "\n",
    "# Create the searchlight object\n",
    "sl = Searchlight(sl_rad=sl_rad, max_blk_edge=max_blk_edge)\n",
    "print(\"Setup searchlight inputs\")\n",
    "print(\"Number of subjects: \" + str(len(data)))\n",
    "print(\"Input data shape: \" + str(data[0].shape))\n",
    "print(\"Input mask shape: \" + str(mask.shape) + \"\\n\")\n",
    "\n",
    "# Distribute the information to the searchlights (preparing it to run)\n",
    "sl.distribute(data, mask)\n",
    "# Data that is needed for all searchlights is sent to all cores via the sl.broadcast function. \n",
    "#In this example, we are sending the labels for classification to all searchlights.\n",
    "sl.broadcast(bcvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> What is the bcvar and how should I use it??? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up the kernel, RDM analysis\n",
    "# def rdm_all(data, sl_mask, myrad, bcvar):\n",
    "#     all_rho = []\n",
    "#     behavior_RDM = None\n",
    "#     # Loop over subject: \n",
    "#     for idx in range(len(data)):\n",
    "#         data4D = data[idx]\n",
    "#         bolddata_sl = data4D.reshape(sl_mask.shape[0] * sl_mask.shape[1] * sl_mask.shape[2], data[0].shape[3]).T\n",
    "#         neural_RDM = np.tril(1-np.corrcoef(bolddata_sl), -1)\n",
    "#         neural_RDM = neural_RDM.ravel()\n",
    "#         neural_RDM = neural_RDM[neural_RDM != 0]\n",
    "#         # TODO get partial corr\n",
    "#         subject_spearman = scipy.stats.spearmanr(neural_RDM, behavior_RDM,axis=None)\n",
    "\n",
    "#         # print(\"bbb\",behavior_RDM.append(neural_RDM))\n",
    "#         # df = pd.DataFrame(data=behavior_RDM.append(neural_RDM), index=['visual','goal','rule','difficulty','neural']).transpose()\n",
    "#         # subject_partial_spearman = pg.partial_corr(data=df, x='neural', y='rule', covar=['visual', 'goal', 'difficulty'],\n",
    "#         #         method='spearman').round(6)\n",
    "#         all_rho.append(subject_spearman.correlation)\n",
    "#     tstats,p = scipy.stats.ttest_1samp(np.arctanh(all_rho), popmean=0)\n",
    "#     return (tstats, p)\n",
    "\n",
    "# # Execute searchlight on 8 subjects\n",
    "# print(\"Begin Searchlight\\n\")\n",
    "# sl_result_allsubj = sl.run_searchlight(rdm_all, pool_size=pool_size)\n",
    "# print(\"End Searchlight\\n\")\n",
    "# print(sl_result_allsubj[mask==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data \n",
    "\n",
    "np.save(path+'diffi_pvalues_all', all_pvalues)\n",
    "\n",
    "np.save(path+'diffi_tstats_all', all_rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quicklinks & resources \n",
    "\n",
    "[brainiak searchlight tutorial](https://brainiak.org/tutorials/07-searchlight/)\n",
    "\n",
    "[brainiak searchlight package](https://brainiak.org/docs/brainiak.searchlight.html#module-brainiak.searchlight)\n",
    "\n",
    "### From `nilearn`\n",
    "\n",
    "- [Searchlight with nilearn](http://nilearn.github.io/auto_examples/02_decoding/plot_haxby_searchlight.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiakEnv",
   "language": "python",
   "name": "brainiakenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
