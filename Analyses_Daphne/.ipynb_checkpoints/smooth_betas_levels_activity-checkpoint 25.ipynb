{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How the intersubject activity evolves across levels\n",
    "\n",
    "--- \n",
    "\n",
    "Here we're asking the question: How does the intersubject similarity evolve across levels? If we pick a certain region, for a given subject, is the intersubject similarity higher or lower across levels? \n",
    "\n",
    "*One prediction is*: if the region is involved in theory updating and learning then we expect a higher similarity for higher levels. As they learn more about the games (i.e. practice) subjects should converge to more similar voxel activation patterns. This might indicate that peoples' representations become more similar (displayed by a larger ISC). In Bayesian terms, people start off with different priors but their posteriors will converge because they get more data. \n",
    "\n",
    "--- \n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1aJrScYoDMPCpz__QT3cXItb4GSyEzb2Z\" style=\"height:400px\"/>\n",
    "\n",
    "## Approach\n",
    "\n",
    "1. We separate the levels betas `[54, voxels]` into 9 arrays of `[games, voxels]`; see image.\n",
    "\n",
    "\n",
    "```Python\n",
    "\n",
    "for each [54, voxels] betas data\n",
    "\n",
    "# take the 1 st item and put together \n",
    "# take the 2nd item and append to something\n",
    "# .... to the 9th item and append\n",
    "\n",
    "# want: [54, voxels] --> [6 (games), 9 (levels)]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "2. Plot 9 brain maps (so far this doesn't seem very promising btw)\n",
    "3. Use the statistical t map to extract the underlying ROIs.\n",
    "    - plot the r values across levels\n",
    "\n",
    "```Python\n",
    "for al ROIs:\n",
    "    \n",
    "  # get the most intense voxel in the ROI\n",
    "\n",
    "  get the x,y,z coordinates that correspond to the highest t statistic\n",
    "    \n",
    "  find the voxel that belongs to this x,y,z coordinate\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "4. With the voxel numbers from Momchil, do an ISC analysis as well and plot the r values for all levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from nilearn import datasets, image\n",
    "from nilearn import surface\n",
    "from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker, NiftiLabelsMasker\n",
    "import nibabel as nib\n",
    "\n",
    "from brainiak import image, io\n",
    "from brainiak.isc import isc, isfc, permutation_isc\n",
    "from brainiak.isc import compute_summary_statistic\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d \n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "from importlib import reload \n",
    "import scipy.io as sio\n",
    "from scipy import stats\n",
    "\n",
    "# import own functions\n",
    "import utils\n",
    "reload(utils)\n",
    "\n",
    "#%autosave 30\n",
    "%matplotlib inline\n",
    "sns.set(style = 'white', context='talk', font_scale=1, rc={\"lines.linewidth\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify local path\n",
    "path = '/Users/Daphne/data/'\n",
    "\n",
    "# load relevant data\n",
    "levels_betas = np.load(path+'bold_data_levels.npy')\n",
    "\n",
    "# load mask and get voxel coordinates\n",
    "mask_arr = np.load(path+'mask_arr.npy') # all masks are the same\n",
    "mask_mat = mask_arr[0] # so we can pick any one from the array\n",
    "coords_mat = np.array(np.where(mask_mat == 1)) # so need one set of voxel coordinates for all\n",
    "coords_mat[[0, 2]] = coords_mat[[2, 0]] # exchange the rows\n",
    "\n",
    "# mask_nii is the functional mask, this selects the brain voxels\n",
    "mask_nii = nib.load(os.path.join(path, 'mask.nii')) \n",
    "\n",
    "# we get the brain mask (boolean array) with the .dataobj method\n",
    "brain_mask = np.array(mask_nii.dataobj)\n",
    "\n",
    "# Get the list of nonzero voxel coordinates from the nii mask\n",
    "coords_nii = np.where(brain_mask)\n",
    "\n",
    "# this where we plot our mask ON (sometimes called brain_nii) - the anatomical/structural image\n",
    "mean_nii = nib.load(os.path.join(path, 'mean.nii')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncomment to sanity check (takes long to load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_levels_betas = pd.read_csv(path+'ordered_betas_df_levels.c\n",
    "# game_names = df_levels_betas['game'].values\n",
    "# game_levels = df_levels_betas['level'].values\n",
    "\n",
    "# print(game_names[0:9])\n",
    "# print(game_levels[0:9])\n",
    "# print(len(game_levels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get every 1st item (all levels 1)\n",
    "# game_levels[0::9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_names[0::9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 220075, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take one subject \n",
    "s = 0\n",
    "levels_betas_sub = levels_betas[:,:,s]\n",
    "levels_betas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Separate data into `9` arrays of  `[6,20075,8] = [games, voxels, subjects]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_level_one = []\n",
    "betas_level_two = []\n",
    "betas_level_three = []\n",
    "betas_level_four = []\n",
    "betas_level_five = []\n",
    "betas_level_six = []\n",
    "betas_level_seven = []\n",
    "betas_level_eight = []\n",
    "betas_level_nine = []\n",
    "\n",
    "num_subjects = 8\n",
    "\n",
    "for s in range(num_subjects):\n",
    "    #print(s)\n",
    "    # take the array for that subject \n",
    "    levels_betas_sub = levels_betas[:,:,s]\n",
    "    \n",
    "    # level 1\n",
    "    lvl_one_betas_sub = levels_betas_sub[0::9]\n",
    "    betas_level_one.append(lvl_one_betas_sub)\n",
    "    \n",
    "    # level 2\n",
    "    lvl_two_betas_sub = levels_betas_sub[1::9]\n",
    "    betas_level_two.append(lvl_two_betas_sub)\n",
    "    \n",
    "    # level 3\n",
    "    lvl_three_betas_sub = levels_betas_sub[2::9]\n",
    "    betas_level_three.append(lvl_three_betas_sub)\n",
    "    \n",
    "    # level 4\n",
    "    lvl_four_betas_sub = levels_betas_sub[3::9]\n",
    "    betas_level_four.append(lvl_four_betas_sub)\n",
    "    \n",
    "    # level 5\n",
    "    lvl_five_betas_sub = levels_betas_sub[4::9]\n",
    "    betas_level_five.append(lvl_five_betas_sub)\n",
    "    \n",
    "    # level 6\n",
    "    lvl_six_betas_sub = levels_betas_sub[5::9]\n",
    "    betas_level_six.append(lvl_six_betas_sub)\n",
    "    \n",
    "    # level 7\n",
    "    lvl_seven_betas_sub = levels_betas_sub[6::9]\n",
    "    betas_level_seven.append(lvl_seven_betas_sub)\n",
    "    \n",
    "    # level 8\n",
    "    lvl_eight_betas_sub = levels_betas_sub[7::9]\n",
    "    betas_level_eight.append(lvl_eight_betas_sub)\n",
    "    \n",
    "    # level 9\n",
    "    lvl_nine_betas_sub = levels_betas_sub[8::9]\n",
    "    betas_level_nine.append(lvl_nine_betas_sub)\n",
    "    \n",
    "# convert lists to np arrays\n",
    "betas_level_one = np.array(betas_level_one)\n",
    "betas_level_two = np.array(betas_level_two)\n",
    "betas_level_three = np.array(betas_level_three)\n",
    "betas_level_four = np.array(betas_level_four)\n",
    "betas_level_five = np.array(betas_level_five)\n",
    "betas_level_six = np.array(betas_level_six)\n",
    "betas_level_seven = np.array(betas_level_seven)\n",
    "betas_level_eight = np.array(betas_level_eight)\n",
    "betas_level_nine = np.array(betas_level_nine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6, 220075)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas_level_one.shape # [subjects, games, voxels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Swapaxes to get data in the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do isc for each level\n",
    "# compute the isc correlations using the leave one out approach\n",
    "betas_level_one = np.swapaxes(betas_level_one, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "betas_level_one = np.swapaxes(betas_level_one, 1, 2)\n",
    "\n",
    "betas_level_two = np.swapaxes(betas_level_two, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "betas_level_two = np.swapaxes(betas_level_two, 1, 2)\n",
    "\n",
    "betas_level_three = np.swapaxes(betas_level_three, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "betas_level_three = np.swapaxes(betas_level_three, 1, 2)\n",
    "\n",
    "betas_level_four = np.swapaxes(betas_level_four, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "betas_level_four = np.swapaxes(betas_level_four, 1, 2)\n",
    "\n",
    "betas_level_five = np.swapaxes(betas_level_five, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "betas_level_five = np.swapaxes(betas_level_five, 1, 2)\n",
    "\n",
    "betas_level_six = np.swapaxes(betas_level_six, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "betas_level_six = np.swapaxes(betas_level_six, 1, 2)\n",
    "\n",
    "betas_level_seven = np.swapaxes(betas_level_seven, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "betas_level_seven = np.swapaxes(betas_level_seven, 1, 2)\n",
    "\n",
    "betas_level_eight = np.swapaxes(betas_level_eight, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "betas_level_eight = np.swapaxes(betas_level_eight, 1, 2)\n",
    "\n",
    "betas_level_nine = np.swapaxes(betas_level_nine, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "betas_level_nine = np.swapaxes(betas_level_nine, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 220075, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 220075, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(betas_level_one.shape)\n",
    "betas_level_two.shape # [all games, voxels, subjects]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISC for all voxels and plot brain maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row or column wise?\n",
    "\n",
    "- column wise (voxels): We do the exact same analysis but then with the betas separated in levels. We ask: for each voxel, how similar are the voxel intensities for level $k$ from one person compared to the average of the other peopele (for all games). \n",
    "\n",
    "---\n",
    "\n",
    "**Note.** `isc_maps_lvl_[...]` are the `r coefficients`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_maps_lvl_one = isc(betas_level_one, pairwise=False, tolerate_nans=True)\n",
    "isc_maps_lvl_two = isc(betas_level_two, pairwise=False, tolerate_nans=True)\n",
    "isc_maps_lvl_three = isc(betas_level_three, pairwise=False, tolerate_nans=True)\n",
    "isc_maps_lvl_four = isc(betas_level_four, pairwise=False, tolerate_nans=True)\n",
    "isc_maps_lvl_five = isc(betas_level_five, pairwise=False, tolerate_nans=True)\n",
    "isc_maps_lvl_six = isc(betas_level_six, pairwise=False, tolerate_nans=True)\n",
    "isc_maps_lvl_seven = isc(betas_level_seven, pairwise=False, tolerate_nans=True)\n",
    "isc_maps_lvl_eight = isc(betas_level_eight, pairwise=False, tolerate_nans=True)\n",
    "isc_maps_lvl_nine = isc(betas_level_nine, pairwise=False, tolerate_nans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 220075)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isc_maps_lvl_one.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps (isc with all voxels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstats, p = stats.ttest_1samp(np.arctanh(isc_maps_lvl_one), popmean=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_statistical_map(coords=coords_mat, \n",
    "                           tstats=tstats, \n",
    "                           pvalues=p, \n",
    "                           brain_nii=mean_nii, \n",
    "                           mask_nii=mask_nii, \n",
    "                           threshold=True,\n",
    "                           theta=0.01,\n",
    "                           cut_coords=[52, 10, 2],\n",
    "                           vmax=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstats, p = stats.ttest_1samp(np.arctanh(isc_maps_lvl_two), popmean=0)\n",
    "\n",
    "utils.plot_statistical_map(coords=coords_mat, \n",
    "                           tstats=tstats, \n",
    "                           pvalues=p, \n",
    "                           brain_nii=mean_nii, \n",
    "                           mask_nii=mask_nii, \n",
    "                           threshold=True,\n",
    "                           theta=0.01,\n",
    "                           cut_coords=[52, 10, 2],\n",
    "                           vmax=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstats, p = stats.ttest_1samp(np.arctanh(isc_maps_lvl_three), popmean=0)\n",
    "\n",
    "utils.plot_statistical_map(coords=coords_mat, \n",
    "                           tstats=tstats, \n",
    "                           pvalues=p, \n",
    "                           brain_nii=mean_nii, \n",
    "                           mask_nii=mask_nii, \n",
    "                           threshold=True,\n",
    "                           theta=0.01,\n",
    "                           cut_coords=[52, 10, 2],\n",
    "                           vmax=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstats, p = stats.ttest_1samp(np.arctanh(isc_maps_lvl_four), popmean=0)\n",
    "\n",
    "utils.plot_statistical_map(coords=coords_mat, \n",
    "                           tstats=tstats, \n",
    "                           pvalues=p, \n",
    "                           brain_nii=mean_nii, \n",
    "                           mask_nii=mask_nii, \n",
    "                           threshold=True,\n",
    "                           theta=0.01,\n",
    "                           cut_coords=[52, 10, 2],\n",
    "                           vmax=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstats, p = stats.ttest_1samp(np.arctanh(isc_maps_lvl_five), popmean=0)\n",
    "\n",
    "utils.plot_statistical_map(coords=coords_mat, \n",
    "                           tstats=tstats, \n",
    "                           pvalues=p, \n",
    "                           brain_nii=mean_nii, \n",
    "                           mask_nii=mask_nii, \n",
    "                           threshold=True,\n",
    "                           theta=0.01,\n",
    "                           cut_coords=[52, 10, 2],\n",
    "                           vmax=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tstats, p = stats.ttest_1samp(np.arctanh(isc_maps_lvl_six), popmean=0)\n",
    "\n",
    "utils.plot_statistical_map(coords=coords_mat, \n",
    "                           tstats=tstats, \n",
    "                           pvalues=p, \n",
    "                           brain_nii=mean_nii, \n",
    "                           mask_nii=mask_nii, \n",
    "                           threshold=True,\n",
    "                           theta=0.01,\n",
    "                           cut_coords=[52, 10, 2],\n",
    "                           vmax=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstats, p = stats.ttest_1samp(np.arctanh(isc_maps_lvl_seven), popmean=0)\n",
    "\n",
    "utils.plot_statistical_map(coords=coords_mat, \n",
    "                           tstats=tstats, \n",
    "                           pvalues=p, \n",
    "                           brain_nii=mean_nii, \n",
    "                           mask_nii=mask_nii, \n",
    "                           threshold=True,\n",
    "                           theta=0.01,\n",
    "                           cut_coords=[52, 10, 2],\n",
    "                           vmax=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstats, p = stats.ttest_1samp(np.arctanh(isc_maps_lvl_eight), popmean=0)\n",
    "\n",
    "utils.plot_statistical_map(coords=coords_mat, \n",
    "                           tstats=tstats, \n",
    "                           pvalues=p, \n",
    "                           brain_nii=mean_nii, \n",
    "                           mask_nii=mask_nii, \n",
    "                           threshold=True,\n",
    "                           theta=0.01,\n",
    "                           cut_coords=[52, 10, 2],\n",
    "                           vmax=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstats, p = stats.ttest_1samp(np.arctanh(isc_maps_lvl_nine), popmean=0)\n",
    "\n",
    "utils.plot_statistical_map(coords=coords_mat, \n",
    "                           tstats=tstats, \n",
    "                           pvalues=p, \n",
    "                           brain_nii=mean_nii, \n",
    "                           mask_nii=mask_nii, \n",
    "                           threshold=True,\n",
    "                           theta=0.01,\n",
    "                           cut_coords=[52, 10, 2],\n",
    "                           vmax=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pick ROIs (one particular voxel at the time) and do the isc analyses for this\n",
    "\n",
    "Ideally, we'd like to pick the top voxel for every blob of in the statistical t map, then use that top voxel to perform an ISC analysis with. There are different ways we can do this. I use two ways\n",
    "\n",
    "[nilearn docs](http://nilearn.github.io/auto_examples/04_manipulating_images/plot_extract_rois_statistical_maps.html#sphx-glr-auto-examples-04-manipulating-images-plot-extract-rois-statistical-maps-py)\n",
    "\n",
    "`functions:`\n",
    "\n",
    "- [threshold_img](http://nilearn.github.io/modules/generated/nilearn.image.threshold_img.html#nilearn.image.threshold_img)\n",
    "- [regions_extracted](http://nilearn.github.io/modules/generated/nilearn.regions.connected_regions.html#nilearn.regions.connected_regions)\n",
    "- [plot_roi](https://nilearn.github.io/modules/generated/nilearn.plotting.plot_roi.html#nilearn.plotting.plot_roi)\n",
    "\n",
    "From the results I got earlier, you see a bunch of blobs in the statistical brain maps. \n",
    "\n",
    "For each of these blobs:\n",
    "\n",
    "    Pick the top voxel (the voxel with the highest t statistic)\n",
    "    Do the isc analysis like the one above but then only for that specific voxel (because that specifies the ROI)\n",
    "    \n",
    "    \n",
    "- `coords` = $[[x_1, y_1, z_1] \\dots [x_k, y_k, z_k]]$ \n",
    "\n",
    "\n",
    "How to extract the regions??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remember we got \n",
    "iscs_r_levels = np.load(path+'iscs_r_levels.npy')\n",
    "tstats_levels, p_levels = stats.ttest_1samp(np.arctanh(iscs_r_levels), popmean=0)\n",
    "\n",
    "# plot the t map and store the nifti image as the statistical image\n",
    "stat_img = utils.plot_statistical_map(coords=coords_mat, \n",
    "                           tstats=tstats_levels, \n",
    "                           pvalues=p_levels, \n",
    "                           brain_nii=mean_nii, \n",
    "                           mask_nii=mask_nii, \n",
    "                           threshold=True,\n",
    "                           theta=0.01,\n",
    "                           cut_coords=[52, 10, 2],\n",
    "                           vmax=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_img # .nii file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = plotting.view_img(stat_img, threshold=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1. Region Extraction using a t-statistical map (3D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import threshold_img\n",
    "from nilearn.regions import connected_regions\n",
    "\n",
    "# threshold the t-statistic image by importing threshold function\n",
    "threshold_value_img = threshold_img(stat_img, threshold='95%', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing intensity threshold image\n",
    "plotting.plot_stat_map(threshold_value_img, bg_img=mean_nii, display_mode='x', cut_coords=5,\n",
    "                       title='Threshold image with intensity value', colorbar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing intensity threshold image\n",
    "plotting.plot_stat_map(threshold_value_img, bg_img=mean_nii, display_mode='y', cut_coords=5,\n",
    "                       title='Threshold image with intensity value', colorbar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing intensity threshold image\n",
    "plotting.plot_stat_map(threshold_value_img, bg_img=mean_nii, display_mode='z', cut_coords=5,\n",
    "                       title='Threshold image with intensity value', colorbar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_extracted_img, index = connected_regions(threshold_value_img,\n",
    "                                                 min_region_size=1350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = (\"ROIs using image intensity thresholding. \"\n",
    "         \"\\n Each ROI in same color is an extracted region\")\n",
    "plotting.plot_prob_atlas(regions_value_img, bg_img=mean_nii,\n",
    "                         view_type='contours', display_mode='x',\n",
    "                         cut_coords=5, title=title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotting.plot_prob_atlas(regions_value_img, bg_img=mean_nii,\n",
    "                         view_type='contours', display_mode='y',\n",
    "                         cut_coords=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_prob_atlas(regions_value_img, bg_img=mean_nii,\n",
    "                         view_type='contours', display_mode='z',\n",
    "                         cut_coords=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_extracted_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_extracted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the masks using .dataobj (boolean arrs) \n",
    "roi_mask_one = regions_extracted_img.dataobj[:,:,:,0]\n",
    "roi_mask_two = regions_extracted_img.dataobj[:,:,:,1]\n",
    "roi_mask_three = regions_extracted_img.dataobj[:,:,:,2]\n",
    "roi_mask_four = regions_extracted_img.dataobj[:,:,:,3]\n",
    "roi_mask_five = regions_extracted_img.dataobj[:,:,:,4]\n",
    "roi_mask_six = regions_extracted_img.dataobj[:,:,:,5]\n",
    "\n",
    "roi_mask_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to nifti object to plot\n",
    "roi_mask_nifti_one = nib.Nifti1Image(roi_mask_one, regions_extracted_img.affine, regions_extracted_img.header) \n",
    "\n",
    "# The mask_nii mask overlayed on mean_nii\n",
    "plotting.plot_roi(roi_img=roi_mask_nifti_one, bg_img=mean_nii, black_bg=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to nifti object to plot\n",
    "roi_mask_nifti_two = nib.Nifti1Image(roi_mask_two, regions_extracted_img.affine, regions_extracted_img.header) \n",
    "\n",
    "# The mask_nii mask overlayed on mean_nii\n",
    "plotting.plot_roi(roi_img=roi_mask_nifti_two, bg_img=mean_nii, black_bg=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to nifti object to plot\n",
    "roi_mask_nifti_three = nib.Nifti1Image(roi_mask_three, regions_extracted_img.affine, regions_extracted_img.header) \n",
    "\n",
    "# The mask_nii mask overlayed on mean_nii\n",
    "plotting.plot_roi(roi_img=roi_mask_nifti_three, bg_img=mean_nii, black_bg=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to nifti object to plot\n",
    "roi_mask_nifti_four = nib.Nifti1Image(roi_mask_four, regions_extracted_img.affine, regions_extracted_img.header) \n",
    "\n",
    "# The mask_nii mask overlayed on mean_nii\n",
    "plotting.plot_roi(roi_img=roi_mask_nifti_four, bg_img=mean_nii, black_bg=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to nifti object to plot\n",
    "roi_mask_nifti_five = nib.Nifti1Image(roi_mask_five, regions_extracted_img.affine, regions_extracted_img.header) \n",
    "\n",
    "# The mask_nii mask overlayed on mean_nii\n",
    "plotting.plot_roi(roi_img=roi_mask_nifti_five, bg_img=mean_nii, black_bg=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to nifti object to plot\n",
    "roi_mask_nifti_six = nib.Nifti1Image(roi_mask_six, regions_extracted_img.affine, regions_extracted_img.header) \n",
    "\n",
    "# The mask_nii mask overlayed on mean_nii\n",
    "plotting.plot_roi(roi_img=roi_mask_nifti_six, bg_img=mean_nii, black_bg=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take the top voxel of each of these masks (roi's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_vol = np.zeros(roi_mask_one.shape) # make zeros volume\n",
    " \n",
    "top_vox = max(np.unique(roi_mask_one)) # this is the max t statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_mask_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_vox_coords = np.where(roi_mask_one==top_vox) # get x,y,z coords for top voxel\n",
    "\n",
    "print(top_vox_coords) # these are the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(top_vox_coords[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, these are coordinates in the mni space? (are they????). So we want to translate this coordinate to voxel space in order to find the right corresponding voxel\n",
    "\n",
    "[image.coord_transform](https://nilearn.github.io/modules/generated/nilearn.image.coord_transform.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "\n",
    "x_mni = int(top_vox_coords[0])\n",
    "y_mni = int(top_vox_coords[1])\n",
    "z_mni = int(top_vox_coords[2])\n",
    "\n",
    "print(x_mni,y_mni,z_mni)\n",
    "\n",
    "# transform from mni to voxel space \n",
    "voxel_space_coords = image.coord_transform(x_mni, y_mni, z_mni, regions_extracted_img.affine)\n",
    "\n",
    "print(voxel_space_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is probably a stupid way to find the corresponding voxel but ok...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(voxel_space_coords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in range(len(all_vox_coords[0])):\n",
    "    \n",
    "    # x,y,z arrays are\n",
    "    x_arr = all_vox_coords[0, :]\n",
    "    y_arr = all_vox_coords[1, :]\n",
    "    z_arr = all_vox_coords[2, :]\n",
    "    \n",
    "    # take coordinates for voxel v\n",
    "    x = x_arr[v]\n",
    "    y = y_arr[v]\n",
    "    z = z_arr[v]\n",
    "\n",
    "#     if x == int(voxel_space_coords[0]) and y == int(voxel_space_coords[1]) and z == int(voxel_space_coords[2]):\n",
    "#         print(f'The coordinates correspond to voxel: {v}. Take the betas for this voxel to do your ISC!')\n",
    "\n",
    "    if x == int(top_vox_coords[0]) and y == int(top_vox_coords[1]) and z == int(top_vox_coords[2]):\n",
    "        top_V = v\n",
    "        print(f'The coordinates correspond to voxel: {top_V}. Take the betas for this voxel to do your ISC!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coords_mat.shape)\n",
    "\n",
    "coords_mat # whole brain mask coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_vox_coords = np.where(roi_mask_one!=0)\n",
    "\n",
    "print(np.array(all_vox_coords).shape)\n",
    "\n",
    "all_vox_coords = np.array(all_vox_coords)\n",
    "\n",
    "all_vox_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tstats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_mask_one[top_vox_coords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to nifti object to plot\n",
    "top_vox_nifti = nib.Nifti1Image(zeros_vol, regions_extracted_img.affine, regions_extracted_img.header) \n",
    "\n",
    "# The mask_nii mask overlayed on mean_nii\n",
    "plotting.plot_roi(roi_img=top_vox_nifti, bg_img=mean_nii, black_bg=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have the top voxel for one ROI, lets do the ISC\n",
    "\n",
    "## First, select the betas only for that voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1, 8)\n"
     ]
    }
   ],
   "source": [
    "# select all items from column 1357 (equivalent to [:, 1350, :] but this keeps it 3D)\n",
    "\n",
    "i = 1356\n",
    "\n",
    "topVox_betas_lvl_one = betas_level_one[:, i:i+1, :]\n",
    "\n",
    "topVox_betas_lvl_two = betas_level_two[:, 1356:1357, :]\n",
    "\n",
    "topVox_betas_lvl_three = betas_level_three[:, 1356:1357, :]\n",
    "\n",
    "topVox_betas_lvl_four = betas_level_four[:, 1356:1357, :]\n",
    "\n",
    "topVox_betas_lvl_five = betas_level_five[:, 1356:1357, :]\n",
    "\n",
    "topVox_betas_lvl_six = betas_level_six[:, 1356:1357, :]\n",
    "\n",
    "topVox_betas_lvl_seven = betas_level_seven[:, 1356:1357, :]\n",
    "\n",
    "topVox_betas_lvl_eight = betas_level_eight[:, 1356:1357, :]\n",
    "\n",
    "topVox_betas_lvl_nine = betas_level_nine[:, 1356:1357, :]\n",
    "# check shape \n",
    "\n",
    "print(topVox_betas_lvl_one.shape) # [games, top voxel, subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.99407732,  0.62705857, -0.12175723, -0.27629802,\n",
       "          0.62239993, -0.77129459,  0.52089119,  0.13649513]],\n",
       "\n",
       "       [[ 0.55955601,  1.43032634,  1.15527189,  0.33163884,\n",
       "          0.05569825, -0.01756327,  0.13032027,  1.57412815]],\n",
       "\n",
       "       [[ 0.0759692 , -0.3428579 ,  0.36849916,  0.28811693,\n",
       "          1.20633268, -0.91309267,  0.38871491, -0.42069376]],\n",
       "\n",
       "       [[ 0.43044406,  0.90647954,  0.9271065 ,  0.52324921,\n",
       "          2.38208508, -0.87047732,  0.42723322,  0.74721503]],\n",
       "\n",
       "       [[ 0.62388813,  1.70070136,  0.10861586, -0.09606238,\n",
       "          1.59888947, -0.48788071, -0.11431514, -0.53684944]],\n",
       "\n",
       "       [[ 0.69866604,  0.79309738,  1.2393645 , -0.02376747,\n",
       "          1.21785903,  0.30070189,  0.69001108, -0.23173241]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topVox_betas_lvl_one_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the ISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_coef_topVox_one = float(isc(topVox_betas_lvl_one , pairwise=False, tolerate_nans=True, summary_statistic='mean'))\n",
    "\n",
    "r_coef_topVox_two = float(isc(topVox_betas_lvl_two , pairwise=False, tolerate_nans=True, summary_statistic='mean'))\n",
    "\n",
    "r_coef_topVox_three = float(isc(topVox_betas_lvl_three , pairwise=False, tolerate_nans=True, summary_statistic='mean'))\n",
    "\n",
    "r_coef_topVox_four = float(isc(topVox_betas_lvl_four , pairwise=False, tolerate_nans=True, summary_statistic='mean'))\n",
    "\n",
    "r_coef_topVox_five = float(isc(topVox_betas_lvl_five , pairwise=False, tolerate_nans=True, summary_statistic='mean'))\n",
    "\n",
    "r_coef_topVox_six = float(isc(topVox_betas_lvl_six, pairwise=False, tolerate_nans=True, summary_statistic='mean'))\n",
    "\n",
    "r_coef_topVox_seven = float(isc(topVox_betas_lvl_seven , pairwise=False, tolerate_nans=True, summary_statistic='mean'))\n",
    "\n",
    "r_coef_topVox_eight = float(isc(topVox_betas_lvl_eight, pairwise=False, tolerate_nans=True, summary_statistic='mean'))\n",
    "\n",
    "r_coef_topVox_nine = float(isc(topVox_betas_lvl_nine, pairwise=False, tolerate_nans=True, summary_statistic='mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21272940409318086"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_coef_topVox_one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_levels_list = [isc_r_topVox_one, isc_r_topVox_two, isc_r_topVox_three, isc_r_topVox_four, isc_r_topVox_five\n",
    "                ,isc_r_topVox_six, isc_r_topVox_seven, isc_r_topVox_eight, isc_r_topVox_nine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_levels_list\n",
    "\n",
    "levels = list(range(1,10)) # for x axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the r values across levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,1, figsize = (12, 5), dpi=50)\n",
    "f.suptitle(f'R values for voxel {3} across levels')\n",
    "ax.bar(levels, r_levels_list, color='b', axes=ax);\n",
    "ax.set_ylabel('r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f'R values for voxel {top_V} across levels')\n",
    "plt.bar(levels, r_levels_list, color='b');\n",
    "plt.ylabel('r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2. Computing the ROI's manually\n",
    "\n",
    "\n",
    "http://nilearn.github.io/auto_examples/04_manipulating_images/plot_roi_extraction.html#sphx-glr-auto-examples-04-manipulating-images-plot-roi-extraction-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiakEnv",
   "language": "python",
   "name": "brainiakenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
