{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Searchlight Analysis </H1>\n",
    "Note: Have to do in condo with virtual env\n",
    "`conda install -c conda-forge openblas=0.2.19`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "# Import libraries\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "from nilearn import plotting\n",
    "from brainiak.searchlight.searchlight import Searchlight\n",
    "from brainiak.fcma.preprocessing import prepare_searchlight_mvpa_data\n",
    "from brainiak import io\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import scipy.stats\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# Set printing precision\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "%autosave 5\n",
    "sns.set(style = 'white', context='poster', rc={\"lines.linewidth\": 2.5})\n",
    "sns.set(palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.2 Executing the searchlight workflow<a id=\"exe_wf\"></a>\n",
    "### 1.2.1 Set searchlight parameters <a id=\"set_param\"></a>\n",
    "\n",
    "To run the [searchlight](http://brainiak.org/docs/brainiak.searchlight.html) function in BrainIAK you need the following parameters:  \n",
    "\n",
    "1. **data** = The brain data as a 4D volume.  \n",
    "2. **mask** = A binary mask specifying the \"center\" voxels in the brain around which you want to perform searchlight analyses. A searchlight will be drawn around every voxel with the value of 1. Hence, if you chose to use the wholebrain mask as the mask for the searchlight procedure, the searchlight may include voxels outside of your mask when the \"center\" voxel is at the border of the mask. It is up to you to decide whether then to include these results.  \n",
    "3. **bcvar** = An additional variable which can be a list, numpy array, dictionary, etc. you want to use in your searchlight kernel. For instance you might want the condition labels so that you can determine to which condition each 3D volume corresponds. If you don't need to broadcast anything, e.g, when doing RSA, set this to 'None'.  \n",
    "4. **sl_rad** = The size of the searchlight's radius, excluding the center voxel. This means the total volume size of the searchlight, if using a cube, is defined as: ((2 * sl_rad) + 1) ^ 3.  \n",
    "5. **max_blk_edge** = When the searchlight function carves the data up into chunks, it doesn't distribute only a single searchlight's worth of data. Instead, it creates a block of data, with the edge length specified by this variable, which determines the number of searchlights to run within a job.  \n",
    "6. **pool_size** = Maximum number of cores running on a block (typically 1).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 220075)\n",
      "(79, 95, 79)\n",
      "(79, 95, 79)\n",
      "[ 2  3  3 ... 74 74 74]\n",
      "[39 40 36 ... 34 35 44]\n"
     ]
    }
   ],
   "source": [
    "# BOLD signals for all subjects, all games (games, voxels, subjects)\n",
    "path = './'\n",
    "all_bold_vol = np.load(path+'bold_data_games.npy')\n",
    "\n",
    "# load mask and get voxel coordinates\n",
    "mask_arr = np.load(path+'mask_arr.npy') # all masks are the same\n",
    "mask_mat = mask_arr[0] # so we can pick any one from the array\n",
    "coords_mat = np.array(np.where(mask_mat == 1)) # so need one set of voxel coordinates for all\n",
    "coords_mat[[0, 2]] = coords_mat[[2, 0]] # exchange the rows\n",
    "print(coords_mat.shape) #coords_mat contains voxel coordinates of brain region voxels\n",
    "\n",
    "# mask_nii is the functional mask, this selects the brain voxels\n",
    "mask_nii = nib.load(os.path.join(path, 'mask.nii')) \n",
    "print(mask_nii.shape)\n",
    "# we get the brain mask (boolean array) with the .dataobj method\n",
    "# brain_mask contains all voxels, 1 at brain regions\n",
    "# coords_mat can be used to index into brain_mask \n",
    "brain_mask = np.array(mask_nii.dataobj)\n",
    "print(brain_mask.shape)\n",
    "affine_mat = mask_nii.affine\n",
    "dimsize = mask_nii.header.get_zooms()\n",
    "\n",
    "# Get the list of nonzero voxel coordinates from the nii mask. SAME AS coords_mat\n",
    "coords_nii = np.where(brain_mask)\n",
    "print(coords_nii[0])\n",
    "print(coords_mat[0])\n",
    "# cords_nii corresponds to the bold_vol <=> verify with Daphne\n",
    "\n",
    "# this where we plot our mask ON (sometimes called brain_nii) - the anatomical/structural image\n",
    "mean_nii = nib.load(os.path.join(path, 'mean.nii')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behavioral RDM\n",
    "behavior_RDM = np.load(path+'behavior_RDM.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup searchlight inputs\n",
      "Number of subjects: 8\n",
      "Input data shape: (79, 95, 79, 6)\n",
      "Input mask shape: (79, 95, 79)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up 4D BOLD for each subject\n",
    "small_mask = np.zeros(brain_mask.shape)\n",
    "small_mask[42, 28, 26] = 1\n",
    "coords = tuple(coords_nii)\n",
    "vol4D = mask_nii.shape+(6,)\n",
    "\n",
    "# For 8 subjects\n",
    "all_bold = []\n",
    "for sub_id in range(8):\n",
    "    isc_vol = np.zeros(vol4D)\n",
    "    bold_vol = all_bold_vol[:,:,sub_id]\n",
    "    for i in range(6):\n",
    "        for j in range(len(coords[0])):\n",
    "            isc_vol[(coords[0][j], coords[1][j], coords[2][j], i)] = bold_vol[i][j]\n",
    "    all_bold.append(isc_vol)\n",
    "\n",
    "# Preset the variables\n",
    "data = all_bold\n",
    "mask = small_mask\n",
    "bcvar = behavior_RDM\n",
    "sl_rad = 1\n",
    "max_blk_edge = 5\n",
    "pool_size = 1\n",
    "\n",
    "# Start the clock to time searchlight\n",
    "begin_time = time.time()\n",
    "\n",
    "# Create the searchlight object\n",
    "sl = Searchlight(sl_rad=sl_rad,max_blk_edge=max_blk_edge)\n",
    "print(\"Setup searchlight inputs\")\n",
    "print(\"Number of subjects: \" + str(len(data)))\n",
    "print(\"Input data shape: \" + str(data[0].shape))\n",
    "print(\"Input mask shape: \" + str(mask.shape) + \"\\n\")\n",
    "\n",
    "# Distribute the information to the searchlights (preparing it to run)\n",
    "sl.distribute(data, mask)\n",
    "# Data that is needed for all searchlights is sent to all cores via the sl.broadcast function. \n",
    "#In this example, we are sending the labels for classification to all searchlights.\n",
    "sl.broadcast(bcvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Searchlight\n",
      "\n",
      "one voxel takes time: 0.01547384262084961 s\n",
      "6.558373922306658 0.0003163431733864217\n",
      "End Searchlight\n",
      "\n",
      "[(6.558373922306658, 0.0003163431733864217)]\n"
     ]
    }
   ],
   "source": [
    "# Set up the kernel, RDM analysis\n",
    "def rdm_all(data, sl_mask, myrad, bcvar):\n",
    "    t1 = time.time()\n",
    "    all_rho = []\n",
    "    behavior_RDM = bcvar\n",
    "    # Loop over subject: \n",
    "    for idx in range(len(data)):\n",
    "        data4D = data[idx]\n",
    "        bolddata_sl = data4D.reshape(sl_mask.shape[0] * sl_mask.shape[1] * sl_mask.shape[2], data[0].shape[3]).T\n",
    "\n",
    "        neural_RDM = 1-np.corrcoef(bolddata_sl)\n",
    "        subject_spearman = scipy.stats.spearmanr(neural_RDM, behavior_RDM,axis=None)\n",
    "        all_rho.append(subject_spearman.correlation)\n",
    "        \n",
    "    tstats,p = scipy.stats.ttest_1samp(np.arctanh(all_rho), popmean=0)\n",
    "    print('one voxel takes time:', time.time() - t1, \"s\")\n",
    "    print(tstats, p)\n",
    "    return (tstats, p)\n",
    "\n",
    "# Execute searchlight on 8 subjects\n",
    "print(\"Begin Searchlight\\n\")\n",
    "sl_result_allsubj = sl.run_searchlight(rdm_all, pool_size=pool_size)\n",
    "print(\"End Searchlight\\n\")\n",
    "print(sl_result_allsubj[mask==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running searchlight analyses on a cluster<a name=\"submitting_searchlights\"></a>\n",
    "\n",
    "**Note: If you are running this section in a non-cluster environment (e.g., a laptop or a server with limited resources), the run-tine for this section can be quite long. You can make an estimate of the run-time (see [exercise 4](#ex4) above) and plan accordingly.**\n",
    "\n",
    "Running searchlight analyses through notebooks or interactive sessions isn't tractable for real studies. Although the example above ran quickly and without parallelization, we only performed 64 analyses. We are now going to write a script to run a searchlight as a \"batch\" job. To learn how to submit jobs, you need to know a bit about [slurm](https://research.computing.yale.edu/support/hpc/user-guide/slurm), the scheduling system we assume you are using. If you are using a different scheduler you will need to follow different instructions. \n",
    "\n",
    "To run a job, a good work flow is to have two scripts: One script that actually does the computation you care about (e.g., a python script like utils.py) and a bash script that sets up the environment and specifies the job parameters. The environment refers to the modules and packages you need to run your job. The job parameters refer to the partition you are going to use (-p), the number of cores (-n), the amount of memory (-m) and required time (-t). To run your job you then call the bash script with something like: 'sbatch script.sh'\n",
    "\n",
    "**Self-study:** Lucky for you we have already written the script needed here, called `run_searchlight.sh`. This script is written in the bash command language. Please explore this script to get familiar with submitting jobs. It will be very useful for future analyses to customize it for your needs (using a text editor like nano or nedit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Paint one voxel onto brain image </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Run it for whole brain voxels </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
