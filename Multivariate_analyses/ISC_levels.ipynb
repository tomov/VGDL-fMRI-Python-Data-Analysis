{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISC analysis with levels\n",
    "\n",
    "> **Remark**. could be the most promising.\n",
    "\n",
    "`beta_series glm25 subj* nosmooth`\n",
    "\n",
    "## Main goals\n",
    "\n",
    "The BOLD signal contains noise. Here, we calculate correlations between subjects to reduce noise and estimate task-relevant signals. Want to find brain regions where the same levels of activity are displayed. Key predictions are that, in the theory encoding region, the ISC should:\n",
    "\n",
    "1. Be highest for same levels, medium for same games, and lowest for random (shuffled) games\n",
    "2. Increase over levels of the same game\n",
    "\n",
    "---\n",
    "\n",
    "## Outline\n",
    "\n",
    "0. Load data in\n",
    "1. Preprocess data\n",
    "    - Clean up strings\n",
    "    - Reorder BOLD data based on names\n",
    "    - \n",
    "3. ISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn import surface\n",
    "from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker, NiftiLabelsMasker\n",
    "import nibabel as nib\n",
    "\n",
    "from brainiak import image, io\n",
    "from brainiak.isc import isc, isfc, permutation_isc\n",
    "from brainiak.isc import compute_summary_statistic\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d \n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "from importlib import reload \n",
    "\n",
    "# import own functions\n",
    "import utils\n",
    "from utils import decode_variable, get_in_shape_levels\n",
    "reload(utils)\n",
    "\n",
    "%autosave 30\n",
    "%matplotlib inline\n",
    "sns.set(style = 'white', context='talk', font_scale=1, rc={\"lines.linewidth\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load in data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/Users/Daphne/Desktop/beta_series/' # local directory \n",
    "filename = 'beta_series_glm25_subj1_nosmooth.mat' # specify filename\n",
    "\n",
    "coords_path = '/Users/Daphne/Desktop/beta_series/'\n",
    "coords_filename = 'coords_nosmooth.mat'\n",
    "\n",
    "os.path.exists(coords_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/Users/Daphne/Desktop/beta_series/beta_series_glm25_subj1_nosmooth.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-70acdeb8d836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msubject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(list(subject.keys()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Get data for subject {idx}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/brainiakEnv/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/brainiakEnv/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/Users/Daphne/Desktop/beta_series/beta_series_glm25_subj1_nosmooth.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "num_subjects = 8\n",
    "\n",
    "B_data = []\n",
    "mask_data = []\n",
    "Vmask_data = []\n",
    "names_data = []\n",
    "\n",
    "for i in range(num_subjects):\n",
    "    idx = i+1\n",
    "    \n",
    "    # change filename to subject #\n",
    "    data_dir = '/Users/Daphne/Desktop/beta_series/'\n",
    "    filename = 'beta_series_glm25_subjk_nosmooth.mat'\n",
    "    filename = filename.replace('k', str(idx))\n",
    "    \n",
    "    subject = h5py.File(data_dir+filename,'r') \n",
    "    #print(list(subject.keys()))\n",
    "    print(f'Get data for subject {idx}')\n",
    "    # load and save data for respective subject\n",
    "    B = subject['B'].value\n",
    "    mask = subject['mask'].value\n",
    "    Vmask = subject['Vmask']\n",
    "    \n",
    "    # === decode level names ===\n",
    "    names = decode_variable(data_dir+filename, 'names')\n",
    "    \n",
    "    # append to lists\n",
    "    B_data.append(B)\n",
    "    mask_data.append(mask)\n",
    "    Vmask_data.append(Vmask)\n",
    "    names_data.append(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B_data[0].shape # voxels x levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-79d40f52b927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "mask_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_data[0].shape # 54 levels (18 blocks x 3 levels per block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(names_data[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get this working\n",
    "#c = h5py.File(coords_path+coords_filename,'r') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing\n",
    "\n",
    "1. Clean the level name strings\n",
    "\n",
    "2. Reorder the BOLD data\n",
    "\n",
    "    - split the list of strings `names` into 3 parts: `game, instance, session`.\n",
    "    - sort the data first by game, then session, then instance (default = quicksort)\n",
    "    - insert a levels column to the ordered dataframes\n",
    "    \n",
    "<font color=red> MEETING: check if the reordering is the same among all matrices. Order: game, session (run), instance.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ISC_data = []\n",
    "ordered_dfs = []\n",
    "clean_names_arr = [] \n",
    "\n",
    "for s in range(num_subjects):\n",
    "    \n",
    "    print(f'Preprocess fMRI data for subject {s+1}')\n",
    "    # get the betas and game order from this\n",
    "    B_s = B_data[s].T # transpose to get [blocks, voxels]\n",
    "    names_s = names_data[s]\n",
    "    \n",
    "    level_names, dfOrdered, B_ordered = get_in_shape_levels(B_s, names_s)\n",
    "    \n",
    "    ISC_data.append(B_ordered)\n",
    "    ordered_dfs.append(dfOrdered)\n",
    "    clean_names_arr.append(level_names)\n",
    "    \n",
    "ISC_arr = np.array(ISC_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the ordering went well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ordered_dfs[0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ordered_dfs[1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_dfs[4].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISC_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISC_arr = np.swapaxes(ISC_arr, 0, 1) # need to get [TRs, voxels, subjects]\n",
    "ISC_arr = np.swapaxes(ISC_arr, 1, 2)\n",
    "\n",
    "ISC_arr.shape # [levels, voxels, subjects]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISC\n",
    "\n",
    "We perform an ISC in two different ways. \n",
    "\n",
    "## 2.1 Do ISC and obtain a matrix\n",
    "\n",
    "We can do an ISC either by treating each row (**block**) as a variable, or by treating each column (**voxel**) as a variable.\n",
    "\n",
    "### Correlating the voxel patterns of the respective blocks\n",
    "\n",
    "- In the study from (Chen et al., 2016) they divided the BOLD data obtained from watching and recalling a Sherlock movie up in 50 scenes. This resulted in one vector voxel values for each recalled scene. As such, they compute the correlation between every matching pair of recalled scenes (see img top right).\n",
    "- In our case, this is equivalent to treating the levels, (i.e. **rows**), as a variable and compute the correlation between each respective level voxel pattern.\n",
    "- <font color=red> MEETING: interpret results, does this make sense? </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_subjects):\n",
    "    \n",
    "    M_sub = ISC_arr[:,:,i] # take the subject matrix \n",
    "    M_rest = np.delete(ISC_arr, i, axis=2) # remove this subjects' data from whole dataset\n",
    "    \n",
    "    #print(M_rest.shape)\n",
    "    # compute average of other matrices\n",
    "    M_rest_mean = np.mean(M_rest, axis=2)\n",
    "    \n",
    "    # now compute correlation between mean matrix & subj matrix\n",
    "    C_blockpatterns = np.corrcoef(M_sub, M_rest_mean, rowvar=True) # treat rows as variables\n",
    "    \n",
    "#     f, ax = plt.subplots(1,1, dpi=100)\n",
    "#     f.suptitle(f'ISC with subject {i+1}')\n",
    "#     sns.heatmap(C_blockpatterns, ax=ax, linewidth=0.3, cmap='bwr', vmin=-1, vmax=1);\n",
    "\n",
    "    mask = np.zeros_like(C_blockpatterns)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    with sns.axes_style(\"white\"):\n",
    "        f, ax = plt.subplots(1,1, dpi=100)\n",
    "        f.suptitle(f'ISC with subject {i+1} | shape {C_blockpatterns.shape}')\n",
    "        ax = sns.heatmap(C_blockpatterns, mask=mask, ax=ax, square=True, cmap='bwr', vmin=-1, vmax=1);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 ISC with Brainiak\n",
    "\n",
    "- we have `ISC_arr` in the form `[levels, voxels, subjects] = (54, 179595, 8)`\n",
    "\n",
    "### Visualise the ISC matrix for one subject back on to the brain to see *where* activity is correlated between participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_maps = isc(ISC_arr, pairwise=False) # The output of ISC is a voxel by \n",
    "                           # participant matrix (showing the result of each individual with the group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_maps.shape # The output of ISC is subjects x voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_maps[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/Daphne/Desktop/beta_series/' # local directory\n",
    "\n",
    "# load in the nift data using nibabel module\n",
    "brain_nii = nib.load(os.path.join(data_dir, 'mask_nosmooth.nii'))\n",
    "\n",
    "brain_nii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- choose a subject (0-7) ---\n",
    "sub = 2\n",
    "\n",
    "# use the mask to find all the coordinates that represent the brain\n",
    "coords_sub = np.where(mask_data[sub] == 1) \n",
    "\n",
    "# Make the ISC output a volume\n",
    "isc_vol = np.zeros(brain_nii.shape)\n",
    "print(isc_vol.shape)\n",
    "\n",
    "# Map the ISC data for a subject into brain space\n",
    "isc_vol[coords_sub].shape\n",
    "\n",
    "isc_maps[sub,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the ISC data for a subject into brain space\n",
    "isc_vol[coords_sub][:-1] = isc_maps[sub,:][:+1] \n",
    "print(isc_vol[coords_sub].shape)\n",
    "print(isc_maps[sub,:].shape)\n",
    "\n",
    "# make a nii image of the isc map \n",
    "isc_nifti = nib.Nifti1Image(isc_vol, brain_nii.affine, brain_nii.header)\n",
    "\n",
    "print(isc_nifti.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as a statmap\n",
    "threshold = .2\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize = (12, 5), dpi=100)\n",
    "plotting.plot_stat_map(\n",
    "    isc_nifti, \n",
    "    threshold=threshold, \n",
    "    axes=ax\n",
    ")\n",
    "ax.set_title(f'ISC map for subject {sub+1}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiakEnv",
   "language": "python",
   "name": "brainiakenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
