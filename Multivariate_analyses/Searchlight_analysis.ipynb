{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searchlight analysis: think outside the box\n",
    "\n",
    "Recall that we think of each $\\beta$ as a point in high dimensional voxel space. We have to choose the voxels in which we want to do the MVPA for two main reasons:\n",
    "   \n",
    "1. **Cog neuro assumes the brain is made up of functional regions.** Based on the relevant unit of analysis (local regions). This idea about the brain as a modular structure comes from Cognitive Neuroscience.\n",
    "2. **Avoid overfitting.** From a statistical point of view, we prefer to have as few dimensions as possible. As such, we'd like to reduce the noise in our dataset by only including the most relevant voxels.\n",
    "   \n",
    "Rule of thumb: we usually take Â±80-100 voxels\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1andZMeSCqfIQSfr7QwIRoYfHP0z7dGTD\" style=\"height:150px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searchlight analysis\n",
    "\n",
    "from ([Joset et al., 2013](https://linkinghub.elsevier.com/retrieve/pii/S1053811913002917))\n",
    "\n",
    "- a type of Multivoxel Pattern Analysis (MVPA), sometimes referred to as *information mapping*.\n",
    "- a *searchlight* is a spatial moving window (kernel) that exhaustively searches the brain to localise representations. SA produces maps by measuring the information (read: variation in signal activity) in small spheres around each voxel.\n",
    "\n",
    "## Searchlight workflow\n",
    "\n",
    "- The two main things that determine the speed of a searchlight: the **kernel algorithm** and the **amount of parallelization**.\n",
    "- Rule of thumb: start your searchlight analysis small!\n",
    "\n",
    "### 1. Prepare the data\n",
    "\n",
    "\n",
    "\n",
    "### 2. Set the searchlight parameters\n",
    "### 3. Create the searchlight object\n",
    "### 4. Create our classification kernel\n",
    "### 5. Execute the searchlight\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Create a mask of one voxel and run the searchlight interactively to check whether the code works.\n",
    "2. Use timestamps to extract the execution time\n",
    "3. Print the number of voxels that are passed to the searchlight function\n",
    "4. Run the searchlight as a job on the smallest unit of real data you have (a single run or single participant)\n",
    "5. Check the runtime and memory usage of this searchlight (e.g. on slurm: `sacct -j $JID --format=jobid,maxvmsize,elapsed`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "# Import libraries\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "from nilearn import plotting\n",
    "from brainiak.searchlight.searchlight import Searchlight\n",
    "from brainiak.fcma.preprocessing import prepare_searchlight_mvpa_data\n",
    "from brainiak import io\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d \n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "from importlib import reload \n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# import own functions\n",
    "import utils\n",
    "from utils import decode_variable, get_in_shape_levels, get_in_shape_blocks, plot_sub_isc_statmap\n",
    "reload(utils)\n",
    "\n",
    "%autosave 30\n",
    "%matplotlib inline\n",
    "sns.set(style = 'white', context='talk', font_scale=1, rc={\"lines.linewidth\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data\n",
    "\n",
    "- want in form `[x,y,z,intensity]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data for subject 1\n",
      "Get data for subject 2\n",
      "Get data for subject 3\n",
      "Get data for subject 4\n",
      "Get data for subject 5\n",
      "Get data for subject 6\n",
      "Get data for subject 7\n",
      "Get data for subject 8\n"
     ]
    }
   ],
   "source": [
    "num_subjects = 8\n",
    "\n",
    "B_data_blocks = []\n",
    "mask_data_blocks = []\n",
    "Vmask_data_blocks = []\n",
    "names_data_blocks = []\n",
    "\n",
    "for i in range(num_subjects):\n",
    "    idx = i+1\n",
    "    \n",
    "    # change filename to subject #\n",
    "    data_dir = '/Users/Daphne/Desktop/beta_series_smooth/'\n",
    "    filename = 'beta_series_glm1_subjk_smooth.mat'\n",
    "    filename = filename.replace('k', str(idx))\n",
    "    \n",
    "    subject = h5py.File(data_dir+filename,'r') \n",
    "    #print(list(subject.keys()))\n",
    "    print(f'Get data for subject {idx}')\n",
    "    # load and save data for respective subject\n",
    "    B = subject['B'].value\n",
    "    mask = subject['mask'].value\n",
    "    Vmask = subject['Vmask']\n",
    "    \n",
    "    # === decode level names ===\n",
    "    names = decode_variable(data_dir+filename, 'names')\n",
    "    \n",
    "    # append to lists\n",
    "    B_data_blocks.append(B)\n",
    "    mask_data_blocks.append(mask)\n",
    "    Vmask_data_blocks.append(Vmask)\n",
    "    names_data_blocks.append(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220075, 18)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "coords = np.where(mask_data_blocks[0] == 1)\n",
    "\n",
    "B_data_blocks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 95, 79)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quicklinks & resources \n",
    "\n",
    "[brainiak searchlight tutorial](https://brainiak.org/tutorials/07-searchlight/)\n",
    "\n",
    "[brainiak searchlight package](https://brainiak.org/docs/brainiak.searchlight.html#module-brainiak.searchlight)\n",
    "\n",
    "### From `nilearn`\n",
    "\n",
    "- [Searchlight with nilearn](http://nilearn.github.io/auto_examples/02_decoding/plot_haxby_searchlight.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiakEnv",
   "language": "python",
   "name": "brainiakenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
