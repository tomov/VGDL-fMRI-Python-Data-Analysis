{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: no access to cluster yet, results are for sub 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Functional connectivity within subjects (standard FC)\n",
    "\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1GPJ8XWcvqHr9NnyVm2DubagzV7cBPvsR\" style=\"height:250px\"/>\n",
    "\n",
    "- The correlation of the time course of activity from the seed voxel with the time series from the target voxel is a proxy for the functional connectivity between those areas. \n",
    "- We have strong hypotheses about how information should flow in the brain. So instead of doing these analyses for the whole brain we do them for specific regions (`==ROI==pairs of voxels`).\n",
    "- BOLD signal is noisy, remove noise and correct for movement $\\rightarrow$ residuals. We do this analysis with the residuals, which is a proxy for the actual BOLD signal. \n",
    "\n",
    "> In other words, FC is a measure of the temporal correlation across different brain areas within a subjects brain.\n",
    "\n",
    "See the [brainiak connectivity tutortial - 08](https://brainiak.org/tutorials/08-connectivity/) for more info.\n",
    "\n",
    "\n",
    "\n",
    "<font color=red></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import h5py\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from nilearn import datasets, image\n",
    "from nilearn import surface\n",
    "from nilearn import plotting\n",
    "from nilearn import input_data\n",
    "\n",
    "from nilearn.input_data import NiftiMasker, NiftiLabelsMasker\n",
    "from nibabel.affines import apply_affine\n",
    "import nibabel as nib\n",
    "import time\n",
    "\n",
    "from brainiak import image, io\n",
    "from brainiak.isc import isc, isfc, permutation_isc\n",
    "from brainiak.isc import compute_summary_statistic\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d \n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "from importlib import reload \n",
    "import scipy.io as sio\n",
    "from scipy import stats\n",
    "from numpy.linalg import inv\n",
    "from numpy import inf\n",
    "from scipy import stats\n",
    "\n",
    "# import own functions\n",
    "import utils\n",
    "reload(utils)\n",
    "\n",
    "sns.set(style = 'white', context='poster', rc={\"lines.linewidth\": 2.5})\n",
    "sns.set(palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load masks, residuals & specify params \n",
    "\n",
    "- Only take the residuals `'R'`, omit the rest of the variables.\n",
    "- Save residuals as `.npy` files so that we can throw away the large files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Daphne/data/residuals_sub1.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7b0da768e933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# residuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'residuals_sub1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/brainiakEnv/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/Daphne/data/residuals_sub1.npy'"
     ]
    }
   ],
   "source": [
    "path = '/Users/Daphne/data/'\n",
    "\n",
    "# mask_nii is the functional mask, this selects the brain voxels\n",
    "mask_nii = nib.load(os.path.join(path, 'mask.nii')) \n",
    "# this where we plot our mask ON (sometimes called brain_nii) - the anatomical/structural image\n",
    "mean_nii = nib.load(os.path.join(path, 'mean.nii')) \n",
    "\n",
    "# inverse of the affine matrix: mni2cor\n",
    "inv_affine = inv(mask_nii.affine) # get the transformation matrix\n",
    "\n",
    "# load mask and get voxel coordinates\n",
    "mask_arr = np.load(path+'mask_arr.npy') # all masks are the same\n",
    "mask_mat = mask_arr[0] # so we can pick any one from the array\n",
    "coords_mat = np.array(np.where(mask_mat == 1)) # so need one set of voxel coordinates for all\n",
    "coords_mat[[0, 2]] = coords_mat[[2, 0]] # exchange the rows\n",
    "\n",
    "# residuals\n",
    "R = np.load(path+'residuals_sub1.npy')\n",
    "R = np.swapaxes(R,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "R.shape # TR x voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('residuals_sub1', R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment and do for all subjects\n",
    "# path = '/Users/Daphne/data/'\n",
    "# filename = 'residuals_glm9_subj1_smooth.mat'\n",
    "\n",
    "# data = h5py.File(path+filename,'r') \n",
    "\n",
    "# print(data.keys())\n",
    "# print(data['R'].value.shape)\n",
    "\n",
    "# residuals_sub1 = data['R'].value R# store residuals for subject\n",
    "\n",
    "# np.save('residuals_sub1', residuals_sub1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pick a seed\n",
    "\n",
    "- We loaded the whole-brain residuals\n",
    "- Now, we pick ROIs (== seed voxel) and correlate their activity with other voxels in the brain\n",
    "- If we find voxels that are correlated with a seed ROI, this suggests that these voxels are functionally connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theory ENCODING voxels\n",
    "R_IFG_Tri_E = [42, 28, 26]\n",
    "L_Insula_E = [-30, 28, 2]\n",
    "R_DMPFC_E = [6, 38, 40]\n",
    "L_IFG_Tri_E = [-50, 44, 12]\n",
    "L_MTG_E = [-64, -50, 4]\n",
    "R_MTG_E = [58, -36, 8]\n",
    "Roi_1A = [48, 34,  8]\n",
    "\n",
    "# Theory UPDATING voxels\n",
    "R_IFG_Oper_U = [48, 12, 28]\n",
    "L_PPC_U = [-56, -32, 46]\n",
    "R_IFG_Tri_U = [52, 38, 16]\n",
    "R_AG_U = [32, -60, 34]\n",
    "L_Fusiform_U = [-40, -58, -12]\n",
    "L_IFG_Oper_U = [-42, 4, 28]\n",
    "R_PHC_U = [26, -42, -8]\n",
    "\n",
    "# control voxels\n",
    "# tip: can always try the contralateral ROIs: [-x y z]\n",
    "L_lingual = [2, -86, 4]\n",
    "Occipital = [-36 -88 -12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to map points to roi names\n",
    "encoding_roi_dict = {'R_IFG_Tri_E':R_IFG_Tri_E, 'L_Insula_E':L_Insula_E, 'R_DMPFC_E':R_DMPFC_E,\n",
    "                     'L_IFG_Tri_E':L_IFG_Tri_E, 'L_MTG_E':L_MTG_E, 'R_MTG_E':R_MTG_E, 'Roi_1A ':Roi_1A \n",
    "                    }\n",
    "\n",
    "updating_roi_dict = {'R_IFG_Oper_U':R_IFG_Oper_U, 'L_PPC_U':L_PPC_U, 'R_IFG_Tri_U':R_IFG_Tri_U,\n",
    "                     'R_AG_U':R_AG_U, 'L_Fusiform_U':L_Fusiform_U, 'L_IFG_Oper_U':L_IFG_Oper_U, \n",
    "                     'R_PHC_U':R_PHC_U\n",
    "                    }\n",
    "\n",
    "# combine in one\n",
    "EU_dict = {**encoding_roi_dict, **updating_roi_dict}\n",
    "\n",
    "# map control voxels to names\n",
    "control_dict = {'control vox (left lingual)':L_lingual, 'control vox (Occipital)':Occipital}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EU_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the voxel indices for the theory encoding and theory updating regions\n",
    "encoding_voxels = []\n",
    "updating_voxels = []\n",
    "\n",
    "# ENCODING ROIs\n",
    "for key, value in encoding_roi_dict.items():\n",
    "\n",
    "    coords_mni = value\n",
    "    print(coords_mni)\n",
    "    \n",
    "    coords_natv = apply_affine(aff=inv_affine, pts=coords_mni) # from mni2cor\n",
    "    vox_num = utils.get_vox_from_coords(coords_mat, coords_natv) # corresponding voxel\n",
    "    \n",
    "    encoding_voxels.append(vox_num)\n",
    "\n",
    "# UPDATING ROIs\n",
    "for key, value in updating_roi_dict.items():\n",
    "\n",
    "    coords_mni = value\n",
    "    print(coords_mni)\n",
    "    \n",
    "    coords_natv = apply_affine(aff=inv_affine, pts=coords_mni) # from mni2cor\n",
    "    vox_num = utils.get_vox_from_coords(coords_mat, coords_natv) # corresponding voxel\n",
    "    \n",
    "    updating_voxels.append(vox_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CHOOSE COORDINATES === (must be MNI)\n",
    "coords_roi = R_IFG_Tri_E\n",
    "coords_control = L_lingual\n",
    "# ==========================\n",
    "\n",
    "# Init the masking object\n",
    "masker_ROI = input_data.NiftiSpheresMasker(\n",
    "    coords_roi, \n",
    "    radius=8, standardize=True, t_r=2.,\n",
    "    memory='nilearn_cache', memory_level=1, verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key(input_dict, value):\n",
    "    return [k for k, v in input_dict.items() if v == value][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_key(roi_dict, coords_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Plot the signal for the ROI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = mask_nii.get_header()\n",
    "hdr.get_xyzt_units() # so we see the voxel size & time units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the corresponding voxel for ROI ...\n",
    "native_coords_roi = apply_affine(aff=inv_affine, pts=coords_roi) # from mni2cor\n",
    "roi_vox = utils.get_vox_from_coords(coords_mat, native_coords_roi) # corresponding voxel\n",
    "\n",
    "# and control voxel\n",
    "native_coords_control = apply_affine(aff=inv_affine, pts=coords_control) # from mni2cor\n",
    "control_vox = utils.get_vox_from_coords(coords_mat, native_coords_control) # corresponding voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the timeseries for the roi and control voxels\n",
    "\"\"\"\n",
    "voxel_ids = [roi_vox, control_vox]\n",
    "\n",
    "plt.figure(figsize=(20, 5), dpi=100)\n",
    "plt.title(f'Voxel activity for voxel ids = {voxel_ids}');\n",
    "plt.plot(R[:, voxel_ids[0]], linewidth=1, label='ROI time series');\n",
    "plt.plot(R[:, voxel_ids[1]], linewidth=1, label='Control time series');\n",
    "plt.ylabel('Evoked activity');\n",
    "plt.xlabel('Timepoints');\n",
    "plt.legend();\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compute the correlations with seed and control voxel\n",
    "\n",
    "- In seed analysis we compute the cross correlation between the time series of the seed voxel and all other voxels. So we just do\n",
    "\n",
    "```Python\n",
    "For all voxels in whole brain mask\n",
    "\n",
    "    correlate with seed voxel\n",
    "```\n",
    "\n",
    "### Caveats\n",
    "\n",
    "- May have different hemodynamic lags in different regions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_with_seed(R, seed_vox):\n",
    "\n",
    "    num_voxels = R.shape[1]\n",
    "    seed_corr = np.zeros((num_voxels, 1)) # make volume to store the correlations\n",
    "    \n",
    "    for v in range(num_voxels):\n",
    "        seed_corr[v, 0] = round(np.corrcoef(R[:,v], R[:, seed_vox])[0,1], 3) # take one value \n",
    "\n",
    "    # Transfrom the correlation values to Fisher z-scores    \n",
    "    seed_corr_fishZ = np.arctanh(seed_corr)\n",
    "    # arctanh(1)=inf so replace inf values with 2.7\n",
    "    seed_corr_fishZ[seed_corr_fishZ == inf] = 2.7\n",
    "\n",
    "    return seed_corr, seed_corr_fishZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_with_control(R, control_vox):\n",
    "\n",
    "    num_voxels = R.shape[1]\n",
    "    control_corr = np.zeros((num_voxels, 1)) # make volume to store the correlations\n",
    "    \n",
    "    for v in range(num_voxels):\n",
    "        control_corr[v, 0] = round(np.corrcoef(R[:,v], R[:, control_vox])[0,1],3) # take one value \n",
    "\n",
    "    # Transfrom the correlation values to Fisher z-scores    \n",
    "    control_corr_fishZ = np.arctanh(control_corr)\n",
    "    # arctanh(1)=inf so replace inf values with 2.7\n",
    "    control_corr_fishZ[control_corr_fishZ == inf] = 2.7\n",
    "\n",
    "    return control_corr, control_corr_fishZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate all with seed voxel\n",
    "corr_roi, corr_fz_roi = corr_with_seed(R=R, seed_vox=roi_vox)\n",
    "\n",
    "# correlate all with control voxel\n",
    "corr_control, corr_fz_control = corr_with_control(R=R, control_vox=control_vox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arctanh(0.99) # becomes inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_fz_roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.isinf(corr_fz_roi).any() # contains inf elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min(corr_fz_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sort(corr_fz_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(corr_roi, bins=30)\n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('r value');\n",
    "plt.xlim([-1,1])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(corr_control, bins=30)\n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('r value');\n",
    "plt.xlim([-1,1])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(corr_fz_control, bins=30)\n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('Fisher-z score');\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(corr_fz_roi, bins=30)\n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('Fisher-z score');\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualise correlations on anatomical image\n",
    "\n",
    "now we want to map the correlations back on the brain???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot the seed correlation with every other voxel\n",
    "- with stat_map\n",
    "- convert correlations to nifti image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[add_markers](https://github.com/nilearn/nilearn/blob/21fdc532dee895b5e46c3fc6a3d4f9803b247ac1/nilearn/plotting/displays.py#L923)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = tuple(coords_mat) # needs to be a tuple in order to work\n",
    "\n",
    "# 1) create a volume from mask_nii\n",
    "volume = np.zeros(mask_nii.shape) \n",
    "\n",
    "# 2) Map the r values into brain space\n",
    "volume[coords] = corr_fz_roi[:,0]\n",
    "\n",
    "# 3) Create a nifti image from this with the affine from mask_nii\n",
    "nii_corr_roi = nib.Nifti1Image(volume, mask_nii.affine, mask_nii.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to reshape in order to plot the seed on nifti object\n",
    "coords_roi_arr = np.array(coords_roi)\n",
    "coords_roi_arr = coords_roi_arr.reshape(1,3)\n",
    "coords_roi_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize = (12, 5), dpi=70)\n",
    "roi_name = find_key(roi_dict, coords_roi)\n",
    "\n",
    "# Nilearn has useful tools for plotting our results as a map\n",
    "r_map_ar = plotting.plot_stat_map(\n",
    "    nii_corr_roi,\n",
    "    threshold=0.6,\n",
    "    cut_coords=coords_roi,\n",
    "    annotate=True,\n",
    "    bg_img=mean_nii,\n",
    "    black_bg=False,\n",
    "    axes=ax,\n",
    ");\n",
    "\n",
    "# Add the seed\n",
    "r_map_ar.add_markers(\n",
    "    marker_coords=coords_roi_arr, \n",
    "    marker_color='g',\n",
    "    marker_size=40,\n",
    ")\n",
    "\n",
    "ax.set_title(f'Fisher z-score values for {roi_name}', size=15); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize = (12, 5), dpi=70)\n",
    "roi_name = find_key(roi_dict, coords_roi)\n",
    "\n",
    "# Create a glass brain\n",
    "plotting.plot_glass_brain(\n",
    "    nii_corr_roi,\n",
    "    axes=ax,\n",
    "    threshold=0.5,\n",
    "    colorbar=True,  \n",
    "    plot_abs=False,\n",
    "    cut_coords=coords_roi,\n",
    "    annotate=True,\n",
    "    bg_img=mean_nii,\n",
    "    black_bg=False,\n",
    "    display_mode='lyrz', \n",
    ");\n",
    "\n",
    "ax.set_title(f'Fisher z-score values for {roi_name}', size=15); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display correlations with control value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = tuple(coords_mat) # needs to be a tuple in order to work\n",
    "\n",
    "# 1) create a volume from mask_nii\n",
    "volume = np.zeros(mask_nii.shape) \n",
    "\n",
    "# 2) Map the r values into brain space\n",
    "volume[coords] = corr_fz_control[:,0]\n",
    "\n",
    "# 3) Create a nifti image from this with the affine from mask_nii\n",
    "nii_corr_control = nib.Nifti1Image(volume, mask_nii.affine, mask_nii.header)\n",
    "\n",
    "# have to reshape in order to plot the seed on nifti object\n",
    "coords_control_arr = np.array(coords_control)\n",
    "coords_control_arr = coords_control_arr.reshape(1,3)\n",
    "coords_control_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize = (12, 5), dpi=70)\n",
    "control_name = find_key(control_dict, coords_control)\n",
    "\n",
    "# Nilearn has useful tools for plotting our results as a map\n",
    "r_map_ar = plotting.plot_stat_map(\n",
    "    nii_corr_control,\n",
    "    threshold=0.6,\n",
    "    cut_coords=coords_control,\n",
    "    annotate=True,\n",
    "    bg_img=mean_nii,\n",
    "    black_bg=False,\n",
    "    axes=ax,\n",
    ");\n",
    "\n",
    "# Add the seed\n",
    "r_map_ar.add_markers(\n",
    "    marker_coords=coords_control_arr, \n",
    "    marker_color='g',\n",
    "    marker_size=40,\n",
    ")\n",
    "\n",
    "ax.set_title(f'Fisher z-score values for {control_name}', size=15); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Correlation matrix and connectome\n",
    "\n",
    "> Correlate the theory updating voxels with the theory encoding voxels\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1RSGslepHFghu4LpvuwmRkcwdRCEYD4DP\" style=\"height:200px\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the voxels we need\n",
    "updating_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the voxels from the residuals\n",
    "updating_time_series = R[:, updating_voxels]\n",
    "encoding_time_series = R[:, encoding_voxels]\n",
    "\n",
    "N = len(encoding_time_series[1])\n",
    "corr_matrix = np.zeros((N,N))\n",
    "\n",
    "\n",
    "for i in range(N): # iterate through voxels (see img above)\n",
    "    \n",
    "    corr_col = []\n",
    "    # pick the ith column from encoding \n",
    "    encoding_vec = encoding_time_series[:, i]\n",
    "    \n",
    "    # correlate it with each col (j) from updating time series\n",
    "    for j in range(N):\n",
    "        \n",
    "        updating_vec = updating_time_series[:, j]\n",
    "        \n",
    "        # correlate column i with column j\n",
    "        corr, _ = stats.pearsonr(encoding_vec, updating_vec)\n",
    "    \n",
    "        corr_col.append(round(corr,2)) \n",
    "    \n",
    "    corr_matrix[:, i] = corr_col # insert correlations into correlation matrix\n",
    "    print(f'--- Theory encoding col {i} ---')\n",
    "    print(corr_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize = (8, 7), dpi=70)\n",
    "\n",
    "sns.heatmap(corr_matrix, \n",
    "            cmap='BuGn',\n",
    "            xticklabels=encoding_roi_dict.keys(),\n",
    "            yticklabels=updating_roi_dict.keys(),\n",
    "            axes=ax,\n",
    "            );\n",
    "\n",
    "ax.set_xlabel('', fontsize=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create symmatric matrix just to make the connectome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_roi_voxels = encoding_voxels + updating_voxels\n",
    "all_roi_time_series = R[:, all_roi_voxels]\n",
    "\n",
    "df = pd.DataFrame(all_roi_time_series) # convert to df\n",
    "sym_corr_matrix = df.corr('pearson') # correlate all cols\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize = (8, 7), dpi=70)\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "#upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    " \n",
    "sns.heatmap(sym_corr_matrix,\n",
    "            cmap='Greens',\n",
    "            xticklabels=EU_dict.keys(),\n",
    "            yticklabels=EU_dict.keys(),\n",
    "            axes=ax\n",
    "            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert null values for the parts where not interested in?? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: add region labels & remove corrs we're not interested in\n",
    "\n",
    "> Display only correlations > threshold\n",
    "\n",
    "[plot_connectome](https://nilearn.github.io/modules/generated/nilearn.plotting.plot_connectome.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize = (8, 7), dpi=100)\n",
    "\n",
    "plotting.plot_connectome(adjacency_matrix=sym_corr_matrix,\n",
    "                         node_coords=np.array(list(EU_dict.values())),\n",
    "                         edge_threshold=0.45,\n",
    "                         edge_cmap='Greens',\n",
    "                         colorbar=True,\n",
    "                         edge_vmax=1,\n",
    "                         edge_vmin=0,\n",
    "                         axes=ax\n",
    "                         );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Granger Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_roi_voxels = encoding_voxels + updating_voxels\n",
    "all_roi_time_series = R[:, all_roi_voxels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_roi_time_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5), dpi=100)\n",
    "plt.plot(all_roi_time_series[:,0])\n",
    "plt.plot(all_roi_time_series[:,1])\n",
    "plt.plot(all_roi_time_series[:,10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5), dpi=100)\n",
    "plt.plot(all_roi_time_series[:,0])\n",
    "plt.plot(all_roi_time_series[:,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement this for all pairs of voxels from above and average over subjects\n",
    "\n",
    "[statsmodels docs](https://www.statsmodels.org/stable/generated/statsmodels.tsa.stattools.grangercausalitytests.html)\n",
    "\n",
    "The Null hypothesis for grangercausalitytests is that the time series in the second column, x2, does NOT Granger cause the time series in the first column, x1. Grange causality means that past values of x2 have a statistically significant effect on the current value of x1, taking past values of x1 into account as regressors. We reject the null hypothesis that x2 does not Granger cause x1 if the pvalues are below a desired size of the test.\n",
    "\n",
    "The null hypothesis for all four test is that the coefficients corresponding to past values of the second time series are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "data = all_roi_time_series[:, [0,7]]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_res = grangercausalitytests(data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiakEnv",
   "language": "python",
   "name": "brainiakenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
